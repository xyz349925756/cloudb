之前部署的失败在于网络，centos8 yum源问题很多，rockylinux 继承centos8，所以同样的问题更改源也没有能够解决问题

过滤 空行和注释行 ：

```sh
[root@controller ~]# grep -Ev '^$|#' /etc/nova/nova.conf
```

==配置文件==缺失==或==者不对可以从：https://docs.openstack.org/ocata/config-reference/networking/samples/ 获取

# 准备

一览表

| 名称       | eth0         | eth1           |
| ---------- | ------------ | -------------- |
| controller | 172.16.0.200 | 192.168.10.200 |
| compute    | 172.16.0.201 | 192.168.10.201 |
|            |              |                |



## 环境

### 网络

```sh
# 设置网络 net.ifnames=0 biosdevname=0  把网卡改成ethx样式的
[root@compute ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
NAME=eth0
UUID=99656878-2188-4919-a959-c8db0a46fd89
DEVICE=eth0
ONBOOT=yes
IPADDR=172.16.0.201
PREFIX=24
GATEWAY=172.16.0.1


ipv4_route_metric=90 优先级
# 修改UUID
[root@losthost ~]# sed -i "/UUID/c UUID=$(uuidgen)" /etc/sysconfig/network-scripts/ifcfg-eth0 

[root@cotroller ~]# cat /etc/resolv.conf 
# Generated by NetworkManager
nameserver 223.5.5.5
nameserver 8.8.4.4
[root@localhost ~]# sed -i 's/114.114.114.114/223.5.5.5/g' /etc/resolv.conf


[root@compute ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth1
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
NAME=eth1
UUID=fd3ff19d-1092-4b53-ac0f-d56f9a924594
DEVICE=eth1
ONBOOT=yes
IPADDR=192.168.10.201
PREFIX=24

controller一样的设置

# 重启网络服务
[root@localhost ~]# systemctl restart NetworkManager

# 终端提示
[root@localhost ~]# vi /etc/bashrc 
 ...
  # You might want to have e.g. tty in prompt (e.g. more virtual machines)
  # and console windows
  # If you want to do so, just add e.g.
  # if [ "$PS1" ]; then
  #   PS1="[\u@\h:\l \W]\\$ "
      PS1='[\[\e[31;40m\]\u\[\e[33;40m\]@\[\e[34;40m\]\h \[\e[33;40m\]\w\[\e[0m\]]\$ '
  # fi
  # to your custom modification shell script in /etc/profile.d/ directory
...
[root@localhost ~]# source /etc/bashrc 

[root@localhost ~]# vim /etc/issue

---------------------------------------------------------------------------------------------
  
 #######  ########  ######## ##    ##  ######  ########    ###     ######  ##    ## 
##     ## ##     ## ##       ###   ## ##    ##    ##      ## ##   ##    ## ##   ##  
##     ## ##     ## ##       ####  ## ##          ##     ##   ##  ##       ##  ##   
##     ## ########  ######   ## ## ##  ######     ##    ##     ## ##       #####    
##     ## ##        ##       ##  ####       ##    ##    ######### ##       ##  ##   
##     ## ##        ##       ##   ### ##    ##    ##    ##     ## ##    ## ##   ##  
 #######  ##        ######## ##    ##  ######     ##    ##     ##  ######  ##    ## 

---------------------------------------------------------------------------------------------

                IP:\4                       TEL:18183510256

---------------------------------------------------------------------------------------------

# 更新yum源 一般不修改
https://developer.aliyun.com/mirror/
[root@localhost ~]# mv /etc/yum.repos.d/CentOS-Base.repo{,.back}   #备份源
[root@localhost ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
[root@localhost ~]# sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo

# epel !!!不能添加
[root@localhost ~]# mv /etc/yum.repos.d/epel.repo{,.bak}

[root@localhost ~]# curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
[root@localhost ~]# yum makecache

#epel源 centos8
[root@compute ~]# dnf install -y https://mirrors.aliyun.com/epel/epel-release-latest-8.noarch.rpm
[root@compute ~]# sed -i 's|^#baseurl=https://download.example/pub|baseurl=https://mirrors.aliyun.com|' /etc/yum.repos.d/epel*
[root@compute ~]# sed -i 's|^metalink|#metalink|' /etc/yum.repos.d/epel*

# 安装常用软件
[root@cotroller ~]# yum install -y tree nmap dos2unix lrzsz nc lsof wget tcpdump htop iftop iotop sysstat nethogs psmisc net-tools bash-completion vim-enhanced bind-utils

# 阿里镜像源 https://developer.aliyun.com/mirror/rockylinux

sed -e 's|^mirrorlist=|#mirrorlist=|g' \
    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
    -i.bak \
    /etc/yum.repos.d/Rocky-*.repo

dnf makecache
```

#### vim 个性化

```sh
[root@cotroller ~]# vim .vimrc
"设置行号"
"set nu"
"自动语法高亮"
"syntax on
"自动缩进"
"set autoindent"
"关闭兼容模式"
"set nocompatible
"激活鼠标"
"set mouse=c"
"开启语法"
"syntax enable
"tab缩进4个空格"
"set tabstop=4"
"设定<< >>移动宽度4"
"set shiftwidth=4
"自动缩进"
"set ai
"智能缩进"
"set si
"显示标尺"
"set ruler
"显示匹配的[]{}"
"set showmatch
"编码设置"
set encoding=utf-8
set fileencodings=utf-8
set termencoding=utf-8
"开启新行时使用智能自动缩进"
"set smartindent
"set cin
"set showmatch
"背景色"
"set background=dark"
"设置光标下划线"
set cursorline

map <F10> : set paste <cr>
map <F11> : set nopaste <cr>

autocmd BufNewFile *.sh exec ":call AddUsr()"
map <F7> ms:call AddTitle()<cr>'s

function AddAuthor()
        let n=1
        while n < 5
                let line = getline(n)
                if line =~'^\s*\*\s*\S*Last\s*modified\s*:\s*\S*.*$'
                        call UpdateTitle()
                        return
                endif
                let n = n + 1
        endwhile
        call AddTitle()
endfunction

function UpdateTitle()
        normal m'
        execute '/* Last modified\s*:/s@:.*$@\=strftime(": %Y-%m-%d %H:%M")@'
        normal "
        normal mk
        execute '/* Filename\s*:/s@:.*$@\=": ".expand("%:t")@'
        execute "noh"
        normal 'k
        echohl WarningMsg | echo "Successful in updating the copy right." | echohl None
endfunction

function AddTitle()
        call append(0,"#!/bin/bash")
        call append(1,"#----------------------------------------------")
        call append(2,"# Author        : 349925756")
        call append(3,"# Email         : 349925756@qq.com")
        call append(4,"# Last modified : ".strftime("%Y-%m-%d %H:%M"))
        call append(5,"# Filename      : ".expand("%:t"))
        call append(6,"# Description   : ")
        call append(7,"# Version       : 1.1 ")
        call append(8,"#----------------------------------------------")
        call append(9," ")
    	call append(10,"#Notes:  ")
        echohl WarningMsg | echo "Successful in adding the copyright." | echohl None

endfunction

function AddUsr()
        call append(0,"#!/bin/bash")
endfunction
```

#### 其他设置

```sh
# 修改主机名
[root@localhost ~]# hostnamectl set-hostname controller
[root@localhost ~]# hostnamectl set-hostname compute

[root@controller ~]# echo -e "192.168.10.200 controller\n192.168.10.201 compute\n" >> /etc/hosts


#互信脚本（都操作）
[root@controller ~]# mkdir -p /server/{soft,scripts}
[root@controller ~]# ssh-keygen -t rsa -b 4096

[root@controller ~]# rpm -ivh sshpass-1.06-2.el7.x86_64.rpm  #提前准备好这个rpm包

[root@controller ~]# vim /server/scripts/push_ssh.sh
#!/bin/bash
hosts=(controller compute)
rpm -qa | grep sshpass 2>&1

[ $? -ne 0 ] && yum install -y sshpass

for h in ${hosts[@]};
do
  echo -e "---------------\033[41;37m  HostName:$h pub-key start\033[0m-----------------";
  sshpass -p$1 ssh-copy-id -i ~/.ssh/id_rsa.pub ${h} "-o StrictHostKeyChecking=no" 2>/dev/null;  
  echo -e "---------------\033[44;37m  HostName:$h pub-key successfull\033[0m-----------------"; 
done   

[root@controller ~]# mv /etc/yum.repos.d/epel.repo{.bak,}   # 不能使用epel


[root@controller ~]# . /server/scripts/push_ssh.sh *****   #你的密码

# 验证
[root@compute ~]# ssh controller hostname -s
controller
[root@compute ~]# ssh controller hostname -i
192.168.10.200

[root@controller ~]# ssh compute hostname -i
192.168.10.201
[root@controller ~]# ssh compute hostname -s
compute
[root@localhost ~]# mv /etc/yum.repos.d/epel.repo{,.bak}

```

### NTP

```sh
# 安装chrony
[root@compute ~]# yum install chrony -y
[root@controller ~]# cp /etc/chrony.conf{,.bak}
[root@controller ~]# vim /etc/chrony.conf
# 对于 RHEL、CentOS 或 SUSE，编辑/etc/chrony.conf文件：
# 这里使用阿里云的NTP服务器
server ntp1.aliyun.com iburst
server ntp2.aliyun.com iburst
server ntp3.aliyun.com iburst
server ntp4.aliyun.com iburst
server ntp5.aliyun.com iburst
server ntp6.aliyun.com iburst


local stratum 10  

# 允许其他节点访问到控制节点
allow 192.168.10.0/24 

[root@controller ~]# systemctl enable chronyd;systemctl start chronyd
[root@controller ~]# systemctl status chronyd|grep Active|awk -F" " '{print $2,$3}'
active (running)

#其他节点
[root@compute ~]# vim /etc/chrony.conf 
server controller iburst    
local stratum 10

[root@compute ~]# systemctl enable chronyd;systemctl start chronyd

# 故障处理
[root@controller ~]# systemctl stop firewalld;systemctl disable firewalld

[root@controller ~]# chronyc sources
210 Number of sources = 2
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* 120.25.115.20                 2   6    37    36   -598us[+6313us] +/-   31ms
^- 203.107.6.88                  2   6    37    35    -10ms[  -10ms] +/-   43ms

[root@compute ~]# chronyc sources
210 Number of sources = 1
MS Name/IP address         Stratum Poll Reach LastRx Last sample               
===============================================================================
^* controller                   10   6    17    26    -17us[  -34us] +/-  897us

#验证
[root@compute ~]# date
Mon Mar 14 23:08:02 CST 2022
[root@controller ~]# date
Mon Mar 14 23:08:02 CST 2022

```



### openstack软件包

```sh
[root@controller ~]# yum search openstack  #检查系统支持包
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: mirrors.bfsu.edu.cn
 * extras: mirrors.cqu.edu.cn
 * updates: mirrors.ustc.edu.cn
====================================================== N/S matched: openstack ======================================================
centos-release-openstack-queens.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-rocky.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-stein.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-train.noarch : OpenStack from the CentOS Cloud SIG repo configs

[root@compute ~]# yum list |grep openstack*  # 跟上面一样的
centos-release-openstack-queens.noarch      1-2.el7.centos             extras   
centos-release-openstack-rocky.noarch       1-1.el7.centos             extras   
centos-release-openstack-stein.noarch       1-1.el7.centos             extras   
centos-release-openstack-train.noarch       1-1.el7.centos             extras  

[root@controller ~]# yum install centos-release-openstack-train -y  #compute一样

[root@controller ~]# ll /etc/yum.repos.d/
total 60
-rw-r--r--. 1 root root 1664 Oct 23  2020 CentOS-Base.repo
-rw-r--r--. 1 root root  956 Jun 19  2019 CentOS-Ceph-Nautilus.repo
-rw-r--r--. 1 root root 1309 Oct 23  2020 CentOS-CR.repo
-rw-r--r--. 1 root root  649 Oct 23  2020 CentOS-Debuginfo.repo
-rw-r--r--. 1 root root  314 Oct 23  2020 CentOS-fasttrack.repo
-rw-r--r--. 1 root root  630 Oct 23  2020 CentOS-Media.repo
-rw-r--r--. 1 root root  717 Mar 24  2020 CentOS-NFS-Ganesha-28.repo
-rw-r--r--. 1 root root 1290 Oct 23  2019 CentOS-OpenStack-train.repo
-rw-r--r--. 1 root root  612 Feb  1  2019 CentOS-QEMU-EV.repo
-rw-r--r--. 1 root root 1331 Oct 23  2020 CentOS-Sources.repo
-rw-r--r--. 1 root root  353 Jul 31  2018 CentOS-Storage-common.repo
-rw-r--r--. 1 root root 8515 Oct 23  2020 CentOS-Vault.repo
-rw-r--r--. 1 root root  616 Oct 23  2020 CentOS-x86_64-kernel.repo

# 安装客户端 和 openstack-selinux软件包以自动管理 OpenStack 服务的安全策略
[root@controller ~]# yum install python-openstackclient openstack-selinux -y
```

### mariadb 

大多数 OpenStack 服务使用 SQL 数据库来存储信息。数据库通常在控制器节点上运行。 MariaDB 或 MySQL。OpenStack 服务还支持其他 SQL 数据库，包括 PostgreSQL

```sh
# 安装sql服务
[root@controller ~]# yum install mariadb mariadb-server python2-PyMySQL -y

# 创建和编辑/etc/my.cnf.d/openstack.cnf文件
[root@controller ~]# cat <<EOF|tee /etc/my.cnf.d/openstack.cnf
[mysqld]
bind-address = $(hostname -i)
default-storage-engine = innodb
innodb_file_per_table = on
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8
EOF

[root@controller ~]# systemctl enable mariadb ;systemctl start mariadb
[root@controller ~]# ss -lnt|grep 3306
LISTEN     0      128    192.168.10.200:3306                     *:*  

# 初始化配置
[root@controller ~]# mysql_secure_installation 
# 配置安全选项，添加用户密码禁用
```

### 消息列队

OpenStack 使用[消息队列](https://docs.openstack.org/install-guide/common/glossary.html#term-message-queue)来协调服务之间的操作和状态信息。消息队列服务通常在控制器节点上运行。OpenStack 支持多种消息队列服务，包括[RabbitMQ](https://www.rabbitmq.com/)、 [Qpid](https://qpid.apache.org/)和[ZeroMQ](http://zeromq.org/)。但是，大多数打包 OpenStack 的发行版都支持特定的消息队列服务。

```sh
# 安装
[root@controller ~]# yum install rabbitmq-server -y

# 启动
[root@controller ~]# systemctl enable rabbitmq-server;systemctl start rabbitmq-server

# 添加openstack用户
[root@controller ~]# rabbitmqctl add_user openstack openstack    # 用户名 密码 格式
Creating user "openstack"

#允许用户进行配置、写入和读取访问openstack
[root@controller ~]# rabbitmqctl set_permissions openstack ".*" ".*" ".*"

# 查看rabbitmp插件列表
[root@controller ~]# rabbitmq-plugins list
 Configured: E = explicitly enabled; e = implicitly enabled
 | Status:   * = running on rabbit@controller
 |/
[  ] amqp_client                       3.6.16
[  ] cowboy                            1.0.4
[  ] cowlib                            1.0.2
[  ] rabbitmq_amqp1_0                  3.6.16
[  ] rabbitmq_auth_backend_ldap        3.6.16
[  ] rabbitmq_auth_mechanism_ssl       3.6.16
[  ] rabbitmq_consistent_hash_exchange 3.6.16
[  ] rabbitmq_event_exchange           3.6.16
[  ] rabbitmq_federation               3.6.16
[  ] rabbitmq_federation_management    3.6.16
[  ] rabbitmq_jms_topic_exchange       3.6.16
[  ] rabbitmq_management               3.6.16
[  ] rabbitmq_management_agent         3.6.16
[  ] rabbitmq_management_visualiser    3.6.16
[  ] rabbitmq_mqtt                     3.6.16
[  ] rabbitmq_random_exchange          3.6.16
[  ] rabbitmq_recent_history_exchange  3.6.16
[  ] rabbitmq_sharding                 3.6.16
[  ] rabbitmq_shovel                   3.6.16
[  ] rabbitmq_shovel_management        3.6.16
[  ] rabbitmq_stomp                    3.6.16
[  ] rabbitmq_top                      3.6.16
[  ] rabbitmq_tracing                  3.6.16
[  ] rabbitmq_trust_store              3.6.16
[  ] rabbitmq_web_dispatch             3.6.16
[  ] rabbitmq_web_mqtt                 3.6.16
[  ] rabbitmq_web_mqtt_examples        3.6.16
[  ] rabbitmq_web_stomp                3.6.16
[  ] rabbitmq_web_stomp_examples       3.6.16
[  ] sockjs                            0.3.4

# 开启web管理界面
[root@controller ~]# rabbitmq-plugins enable rabbitmq_management
The following plugins have been enabled:
  amqp_client
  cowlib
  cowboy
  rabbitmq_web_dispatch
  rabbitmq_management_agent
  rabbitmq_management

Applying plugin configuration to rabbit@controller... started 6 plugins.

# 15672是web访问端口
[root@controller ~]# netstat -lntup|grep 5672
tcp        0      0 0.0.0.0:25672           0.0.0.0:*               LISTEN      8963/beam           
tcp        0      0 0.0.0.0:15672           0.0.0.0:*               LISTEN      8963/beam           
tcp6       0      0 :::5672                 :::*                    LISTEN      8963/beam         
```

http://controller:15672/  访问rabbitMQ   user:guest  password:guest

![image-20220329103200939](openstack_version2.assets/image-20220329103200939.png)

![image-20220405165855314](openstack_version2.assets/image-20220405165855314.png)

![image-20220405165912453](openstack_version2.assets/image-20220405165912453.png)

### memcache

identity服务使用memcache作为缓存服务。控制器运行

```sh
# 安装
[root@controller ~]# yum install memcached python-memcached -y

# 编辑/etc/sysconfig/memcached
-- 将服务配置为使用控制器节点的管理 IP 地址。这是为了允许其他节点通过管理网络访问
[root@controller ~]# vim /etc/sysconfig/memcached
PORT="11211"
USER="memcached"
MAXCONN="1024"
CACHESIZE="1024"
OPTIONS="-l 127.0.0.1,::1,controller"   

# 启动
[root@controller ~]# systemctl enable memcached;systemctl start memcached
```



### Etcd

存储键值对，kubernetes就是基于ETCD

```sh
# install
[root@controller ~]# yum install etcd -y

# 编辑/etc/etcd/etcd.conf文件
[root@controller ~]# grep '^[a-Z]' /etc/etcd/etcd.conf
#[Member]
ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
ETCD_LISTEN_PEER_URLS="http://192.168.10.200:2380"
ETCD_LISTEN_CLIENT_URLS="http://192.168.10.200:2379"
ETCD_NAME="controller"
#[Clustering]
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.168.10.200:2380"
ETCD_ADVERTISE_CLIENT_URLS="http://192.168.10.200:2379"
ETCD_INITIAL_CLUSTER="controller=http://192.168.10.200:2380"
ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"
ETCD_INITIAL_CLUSTER_STATE="new"

#启动
[root@controller ~]# systemctl enable etcd;systemctl start etcd
```



# 安装openstack服务

上面openstack检查的时候就发现centos7 最高就是T版 train

```sh
[root@controller ~]# yum search centos-release-openstack
centos-release-openstack-queens.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-rocky.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-stein.noarch : OpenStack from the CentOS Cloud SIG repo configs
centos-release-openstack-train.noarch : OpenStack from the CentOS Cloud SIG repo configs
```

## keystone

身份验证服务：identity

OpenStack Identity 服务提供了用于管理身份验证、授权和服务目录的单点集成。

OpenStack 支持多个区域以实现可扩展性。`RegionOne`地区。在身份服务中创建的区域、服务和端点共同构成了部署的服务目录。部署中的每个 OpenStack 服务都需要一个服务条目，其对应的端点存储在 Identity 服务中。这一切都可以在安装和配置身份服务后完成。

身份服务包含以下组件：

- ==服务器==

  集中式服务器使用 RESTful 接口提供身份验证和授权服务。

- ==驱动程序==

  驱动程序或服务后端集成到集中式服务器。它们用于访问 OpenStack 外部存储库中的身份信息，并且可能已经存在于部署 OpenStack 的基础架构中（例如，SQL 数据库或 LDAP 服务器）。

- ==模块==

  中间件模块在使用身份服务的 OpenStack 组件的地址空间中运行。这些模块拦截服务请求，提取用户凭据，并将其发送到集中式服务器进行授权。中间件模块和 OpenStack 组件之间的集成使用 Python Web 服务器网关接口。
  
  ![img](openstack_version2.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MzU2NzU3Mw==,size_16,color_FFFFFF,t_70#pic_center.png)

### 安装和配置

https://docs.openstack.org/keystone/train/install/index-rdo.html

这里因为下面是每个服务重复的部分，写一个脚本实现

```sh
# 创建数据库并授权
[root@controller ~]# vim /server/scripts/create_database.sh 

#!/bin/bash
CMD="mysql -uroot -phongfei007 -e"
services=(keystone glance placement neutron cider)
novas=(nova nova_api nova_cell0)
for s in ${services[@]};
do
  ${CMD} "create database ${s};"
  ${CMD} "grant all privileges on ${s}.* to '${s}'@'localhost' identified by '${s}'";
  ${CMD} "grant all privileges on ${s}.* to '${s}'@'%' identified by '${s}'";
done

for n in ${novas[@]};
do
  ${CMD} "create database ${n}";                                                                                                                 
  ${CMD} "grant all privileges on ${n}.* to 'nova'@'localhost' identified by 'nova'";
  ${CMD} "grant all privileges on ${n}.* to 'nova'@'%' identified by 'nova'";
done


# 验证每个用户对应的数据库
[root@controller ~]# vim /server/scripts/verify_database.sh 

#!/bin/bash
services=(keystone glance placement neutron cider)
novas=(nova nova_api nova_cell0)
for d in ${services[@]};
do
   mysql -u${d} -p${d} -e "show databases;use ${d};show tables";
done

for n in ${novas[@]};
do
   mysql -unova -pnova -e "show databases;use ${n};show tables";                                                                                 
done

mysql -uroot -p$1 -e "select host,user from mysql.user";

```

验证脚本，现在还没有数据，后期有数据show tables才看得到，现在是空

```sh
[root@controller ~]# . /server/scripts/create_database.sh  #创建数据
[root@controller ~]# . /server/scripts/verify_database.sh *****(password)  #验证用户及对应的数据库
+--------------------+
| Database           |
+--------------------+
| information_schema |
| keystone           |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| glance             |
| information_schema |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| information_schema |
| placement          |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| information_schema |
| neutron            |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| cider              |
| information_schema |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| information_schema |
| nova               |
| nova_api           |
| nova_cell0         |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| information_schema |
| nova               |
| nova_api           |
| nova_cell0         |
+--------------------+
+--------------------+
| Database           |
+--------------------+
| information_schema |
| nova               |
| nova_api           |
| nova_cell0         |
+--------------------+
+-----------+-----------+
| host      | user      |
+-----------+-----------+
| %         | cider     |
| %         | glance    |
| %         | keystone  |
| %         | neutron   |
| %         | nova      |
| %         | placement |
| 127.0.0.1 | root      |
| ::1       | root      |
| localhost | cider     |
| localhost | glance    |
| localhost | keystone  |
| localhost | neutron   |
| localhost | nova      |
| localhost | placement |
| localhost | root      |
+-----------+-----------+
```

#### 组件

```sh
# install
[root@controller ~]# yum install openstack-keystone httpd mod_wsgi -y

#编辑/etc/keystone/keystone.conf
[root@controller ~]# cp /etc/keystone/keystone.conf{,.bak}
[root@controller ~]# vim /etc/keystone/keystone.conf 
582 [database]
601 connection = mysql+pymysql://keystone:keystone@controller/keystone 
2447 [token]
2477 provider = fernet   #配置 Fernet 令牌提供程序

```

填充keystone数据

```sh
[root@controller ~]# su -s /bin/sh -c "keystone-manage db_sync" keystone

# 验证
[root@controller ~]# mysql -ukeystone -pkeystone -e "use keystone;show tables;"
```

初始化fernet密钥存储库   以下命令会生成两个密钥，生成的密钥放于/etc/keystone/目录下，用于加密数据

```sh
[root@controller ~]# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
[root@controller ~]# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
```

引导身份服务  #admin是密码

```sh
root@controller ~]# keystone-manage bootstrap --bootstrap-password admin \
  --bootstrap-admin-url http://controller:5000/v3/ \
  --bootstrap-internal-url http://controller:5000/v3/ \
  --bootstrap-public-url http://controller:5000/v3/ \
  --bootstrap-region-id RegionOne
```

配置apache

```sh
# 编辑/etc/httpd/conf/httpd.conf
[root@controller ~]# cp /etc/httpd/conf/httpd.conf{,.bak}
 96 ServerName controller:80     

# 创建/usr/share/keystone/wsgi-keystone.conf文件的链接 安装完mod_wsgi包后，会生成 wsgi-keystone.conf 这个文件，文件中配置了虚拟主机及监听了5000端口，mod_wsgi就是python的网关

[root@controller ~]# ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/

[root@controller ~]# ll /etc/httpd/conf.d/
total 16
-rw-r--r--. 1 root root 2926 Jan 25 22:08 autoindex.conf
-rw-r--r--. 1 root root  366 Jan 25 22:09 README
-rw-r--r--. 1 root root 1252 Jan  8 00:08 userdir.conf
-rw-r--r--. 1 root root  824 Jan 14 01:38 welcome.conf
lrwxrwxrwx. 1 root root   38 Mar 16 10:12 wsgi-keystone.conf -> /usr/share/keystone/wsgi-keystone.conf
```

ssl更安全一些

```sh
[root@controller ~]# systemctl enable httpd;systemctl start httpd

# 失败是selinux开启 
sed -i "s/SELINUX=.*/SELINUX=disabled/g" /etc/selinux/config 

[root@controller ~]# ss -lntu|grep 5000
tcp    LISTEN     0      128    [::]:5000               [::]:*   
```

可以把上面的信息创建为环境变量

```sh
[root@controller ~]# vim .bashrc 

# .bashrc

# User specific aliases and functions

alias rm='rm -i'
alias cp='cp -i'
alias mv='mv -i'

# Source global definitions
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi

export OS_USERNAME=admin
export OS_PASSWORD=admin
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3    

[root@controller ~]# . .bashrc
```

此处显示的这些值是从创建的默认值。`keystone-manage bootstrap`

替换为[keystone-install-configure-rdo](https://docs.openstack.org/keystone/train/install/keystone-install-rdo.html#keystone-install-configure-rdo)中命令中`ADMIN_PASS`使用的密码 。`keystone-manage bootstrap`



#### 创建域，项目，用户和角色

Identity 服务为每个 OpenStack 服务提供身份验证服务。身份验证服务使用域、项目、用户和角色的组合。

```sh
# 创建域 示例
[root@controller ~]# source .bashrc  #加载上面的环境变量
[root@controller ~]# openstack domain create --description "cloudb.pub" cloudb
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | cloudb.pub                       |
| enabled     | True                             |
| id          | 9e32e32e1b16410a84cc2bb3b4557030 |
| name        | cloudb                           |
| options     | {}                               |
| tags        | []                               |
+-------------+----------------------------------+


#创建service
[root@controller ~]# openstack project create --domain default --description "Service Project" service
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Service Project                  |
| domain_id   | default                          |
| enabled     | True                             |
| id          | 557e5afbd0c64ec996af34f3b9285936 |
| is_domain   | False                            |
| name        | service                          |
| options     | {}                               |
| parent_id   | default                          |
| tags        | []                               |
+-------------+----------------------------------+
```

上面是例子跟实例无关

创建一个mypeoject项目和myuser用户用于实例

```sh
[root@controller ~]# openstack domain list
+---------+---------+---------+--------------------+
| ID      | Name    | Enabled | Description        |
+---------+---------+---------+--------------------+
| default | Default | True    | The default domain |
+---------+---------+---------+--------------------+

# 创建mypeoject项目
[root@controller ~]# openstack project create --domain default --description "Demo Project" myproject
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Demo Project                     |
| domain_id   | default                          |
| enabled     | True                             |
| id          | d8a0a1caeb7c4a24b9172583d5334f73 |
| is_domain   | False                            |
| name        | myproject                        |
| options     | {}                               |
| parent_id   | default                          |
| tags        | []                               |
+-------------+----------------------------------+

# 在默认域创建myuser用户
[root@controller ~]# openstack user create --domain default --password-prompt myuser
User Password:  myuser
Repeat User Password:  myuser
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 712d99082a9c4244a10aeae357d84c09 |
| name                | myuser                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+

# 创建myrole角色
[root@controller ~]# openstack role create myrole
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | None                             |
| id          | 92fbed018075451191e9e6d90ba39f6e |
| name        | myrole                           |
| options     | {}                               |
+-------------+----------------------------------+

# 将myproject myuser添加到myrole角色
[root@controller ~]# openstack role add --project myproject --user myuser myrole

```

检查

```sh
[root@controller ~]# openstack user list
+----------------------------------+--------+
| ID                               | Name   |
+----------------------------------+--------+
| 6127f8fe9b20457b9fccce922fb34981 | admin  |
| 712d99082a9c4244a10aeae357d84c09 | myuser |
+----------------------------------+--------+

[root@controller ~]# openstack project list
+----------------------------------+-----------+
| ID                               | Name      |
+----------------------------------+-----------+
| 557e5afbd0c64ec996af34f3b9285936 | service   |
| 81e9a381f87f4a9a9c4ac1bc39248b67 | admin     |
| e970d927dd1d4872a3d6904203ef548a | myproject |
+----------------------------------+-----------+

[root@controller ~]# openstack role list
+----------------------------------+--------+
| ID                               | Name   |
+----------------------------------+--------+
| 47d61ed21aa7493da59c68af0c11a4bf | member |
| 7fd622c684b14f82a73e773d07da41bf | admin  |
| 92fbed018075451191e9e6d90ba39f6e | myrole |
| e77db4bda5ad488faa31271934f75d3f | reader |
+----------------------------------+--------+

[root@controller ~]# openstack domain list
+---------+---------+---------+--------------------+
| ID      | Name    | Enabled | Description        |
+---------+---------+---------+--------------------+
| default | Default | True    | The default domain |
+---------+---------+---------+--------------------+
```

#### 验证

```sh
# 取消环境变量中的OS_AUTH_URL和OS_PASSWORD 
[root@controller ~]# unset OS_AUTH_URL OS_PASSWORD

# 为admin请求一个token
[root@controller ~]# openstack --os-auth-url http://controller:5000/v3 \
  --os-project-domain-name Default --os-user-domain-name Default \
  --os-project-name admin --os-username admin token issue
Password:   #admin 的密码
+------------+----------------------------------------------------------+
| Field      | Value                                                    |
+------------+----------------------------------------------------------+
| expires    | 2022-03-16T06:47:07+0000                                 |
| id         | gAAAAABiQpolT525oxoWpb9NAs1en6Ket_-beVWbsR8bEEqhGgAY7xRSEiCwv5UOyX6LpYEna890oOYO1DqhysScmgReZR0blkE9mXsMfyFp3PCaJ9Creb-DYyo_73QqTxj_miIjCAX58akkwiYo71Lmldfh2VSFEzfEcbVRLgZXvumlirf255w        |
| project_id | 81e9a381f87f4a9a9c4ac1bc39248b67                         |
| user_id    | 6127f8fe9b20457b9fccce922fb34981                         |
+------------+----------------------------------------------------------+

# 为myuser请求一个token
[root@controller ~]# openstack --os-auth-url http://controller:5000/v3 \
  --os-project-domain-name Default --os-user-domain-name Default \
  --os-project-name myproject --os-username myuser token issue
```

#### 创建openstack 客户端环境脚本

此脚本注意安全

```sh
# 创建并编辑admin-openrc文件并添加以下内容
[root@controller ~]# vim /server/scripts/admin-openrc
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=admin
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2

# demo-openrc
[root@controller ~]# vim /server/scripts/demo-openrc
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=myproject
export OS_USERNAME=myuser
export OS_PASSWORD=myuser
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
```

使用脚本

```sh
[root@controller ~]# . /server/scripts/admin-openrc 
[root@controller ~]# openstack token issue
+------------+------------------------------------------------------------------------------+
| Field      | Value                                                                        |
+------------+------------------------------------------------------------------------------+
| expires    | 2022-03-16T06:55:27+0000                                                     |
| id         | gAAAAABiMXvPK8bgefyuJSKUB2XqqL4IPku62LeNs4SRIMA2oulTybwhcsNZVk4O5eYeu-w4kLdaVmiaM9M6ry47SKNb8FLzSFLoKcTPck-ENhxm3Itpq_sGYsPjsRd3YoPeJSL9-lDIqreZIgAt-XzVot2DIjRp8bmiUbAXxWILLWbTUIWStNQ |
| project_id | 30eb9394d8234f6fa90de8fc83d9839c                                             |
| user_id    | 8b81c2b3ef7440b186faf94e6893f355                                             |
+------------+------------------------------------------------------------------------------+

```

## Glance

### 条件

[先决条件](###安装和配置)已经在上面使用脚本完成

```sh
# 加载admin变量
[root@controller ~]# . /server/scripts/admin-openrc 

# 创建服务账户
[root@controller ~]# openstack user create --domain default --password-prompt glance
User Password:  glance
Repeat User Password:   glance
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | cce19ff79c8e45a7b8fed99436f40517 |
| name                | glance                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+

# 添加glance用户关联到service项目的admin角色
[root@controller ~]# openstack role add --project service --user glance admin

# 创建glance服务实体
[root@controller ~]# openstack service create --name glance --description "OpenStack Image" image
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Image                  |
| enabled     | True                             |
| id          | 6425ed4306ed4e918cd13c4c7497879a |
| name        | glance                           |
| type        | image                            |
+-------------+----------------------------------+

# 检查
[root@controller ~]# openstack service list
+----------------------------------+----------+----------+
| ID                               | Name     | Type     |
+----------------------------------+----------+----------+
| 2edd3357affa4d70ab33a6fa14126b58 | glance   | image    |
| 98031f7ac52c4972b25be11c7ef5b5a6 | keystone | identity |
+----------------------------------+----------+----------+
```

创建imageAPI接口

```sh
# 公共接口
[root@controller ~]# openstack endpoint create --region RegionOne image public http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | ec69aa7e54484d16a6e27931aa05ebc4 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6425ed4306ed4e918cd13c4c7497879a |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+


# 私有接口
[root@controller ~]# openstack endpoint create --region RegionOne image internal http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 5caa61c4809f43d3b59c7980a1427768 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6425ed4306ed4e918cd13c4c7497879a |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+

# admin 接口
[root@controller ~]# openstack endpoint create --region RegionOne image admin http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 9a8880fcc902452aae4f856025e55716 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6425ed4306ed4e918cd13c4c7497879a |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+

[root@controller ~]# openstack endpoint list
+----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+
| ID                               | Region    | Service Name | Service Type | Enabled | Interface | URL                        |
+----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+
| 3faa8f09eee24818ad7b1e484f993476 | RegionOne | keystone     | identity     | True    | public    | http://controller:5000/v3/ |
| 5caa61c4809f43d3b59c7980a1427768 | RegionOne | glance       | image        | True    | internal  | http://controller:9292     |
| 5eb7538422a24d8fbbaa93794768701c | RegionOne | keystone     | identity     | True    | internal  | http://controller:5000/v3/ |
| 76d56baa8adc4e97840c87688ae6c1c7 | RegionOne | keystone     | identity     | True    | admin     | http://controller:5000/v3/ |
| 9a8880fcc902452aae4f856025e55716 | RegionOne | glance       | image        | True    | admin     | http://controller:9292     |
| ec69aa7e54484d16a6e27931aa05ebc4 | RegionOne | glance       | image        | True    | public    | http://controller:9292     |
+----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+

```

### install  and configure

```sh
# install
[root@controller ~]# yum install openstack-glance -y

# configure /etc/glance/glance-api.conf
[root@controller ~]# cp /etc/glance/glance-api.conf{,.bak}
2071 [database]
2090 connection = mysql+pymysql://glance:glance@controller/glance

4859 [keystone_authtoken] 
4874 www_authenticate_uri = http://controller:5000   
4876 auth_url = http://controller:5000
4877 memcached_servers = controller:11211
4878 auth_type = password
4879 project_domain_name = Default
4880 user_domain_name = Default
4881 project_name = service
4882 username = glance
4883 password = glance  

5505 [paste_deploy]   
5535 flavor = keystone

3349 [glance_store]  
3410 stores = file,http   
3464 default_store = file  
3749 filesystem_store_datadir = /var/lib/glance/images/
```

```sh
# 填充glance数据库
[root@controller ~]# su -s /bin/sh -c "glance-manage db_sync" glance
-- 忽略提示信息
```

启动

```sh
[root@controller ~]# systemctl enable openstack-glance-api;systemctl start openstack-glance-api
[root@controller ~]# ss -lntu|grep 9292
tcp    LISTEN     0      128       *:9292                  *:*      

```

### 验证

```sh
# 加载admin变量信息
[root@controller ~]# . /server/scripts/admin-openrc 

# 下载测试镜像
[root@controller ~]# wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img

# 转换格式为QCOW2，
[root@controller ~]# glance image-create --name "cirros" \
  --file cirros-0.4.0-x86_64-disk.img \
  --disk-format qcow2 --container-format bare \
  --visibility public
+------------------+----------------------------------------------------------------------------------+
| Property         | Value                                                                            |
+------------------+----------------------------------------------------------------------------------+
| checksum         | 443b7623e27ecf03dc9e01ee93f67afe                                                 |
| container_format | bare                                                                             |
| created_at       | 2022-03-29T06:13:34Z                                                             |
| disk_format      | qcow2                                                                            |
| id               | 19ed976e-a52f-43da-b523-fcb0a94a7b40                                             |
| min_disk         | 0                                                                                |
| min_ram          | 0                                                                                |
| name             | cirros                                                                           |
| os_hash_algo     | sha512                                                                           |
| os_hash_value    | 6513f21e44aa3da349f248188a44bc304a3653a04122d8fb4535423c8e1d14cd6a153f735bb0982e |
|                  | 2161b5b5186106570c17a9e58b64dd39390617cd5a350f78                                 |
| os_hidden        | False                                                                            |
| owner            | 81e9a381f87f4a9a9c4ac1bc39248b67                                                 |
| protected        | False                                                                            |
| size             | 12716032                                                                         |
| status           | active                                                                           |
| tags             | []                                                                               |
| updated_at       | 2022-03-29T06:13:35Z                                                             |
| virtual_size     | Not available                                                                    |
| visibility       | public                                                                           |
+------------------+----------------------------------------------------------------------------------+

# 确认上传图片属性
[root@controller ~]# glance image-list
+--------------------------------------+--------+
| ID                                   | Name   |
+--------------------------------------+--------+
| 19ed976e-a52f-43da-b523-fcb0a94a7b40 | cirros |
+--------------------------------------+--------+
```

## Placement

Placement 提供了一个`placement-api`WSGI 脚本，用于使用 Apache、nginx 或其他支持 WSGI 的 Web 服务器运行服务。

### 准备

[先决条件](###安装和配置)

```sh
# configrue 
[root@controller ~]# . /server/scripts/admin-openrc 

# 创建placement 用户
[root@controller ~]# openstack user create --domain default --password-prompt placement
User Password:   placement
Repeat User Password:   placement
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 3fec6736f3684b22b10954ba83695efb |
| name                | placement                        |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+

# 将用户添加到service 项目 admin角色
[root@controller ~]# openstack role add --project service --user placement admin

#创建placement API 条目
[root@controller ~]# openstack service create --name placement --description "Placement API" placement
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Placement API                    |
| enabled     | True                             |
| id          | 44f5f7ee6ade4256824e3a346de19240 |
| name        | placement                        |
| type        | placement                        |
+-------------+----------------------------------+
```

创建placement API

```sh
[root@controller ~]# openstack endpoint create --region RegionOne placement public http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | e43e26896255438892cbbf5846cceef3 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 44f5f7ee6ade4256824e3a346de19240 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+

[root@controller ~]# openstack endpoint create --region RegionOne placement internal http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | e9a27c37d13a4bb1a884cfe24ce73201 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 44f5f7ee6ade4256824e3a346de19240 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+

[root@controller ~]# openstack endpoint create --region RegionOne placement admin http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | e5519a9bd81a4c17af66aa4959a49d26 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 44f5f7ee6ade4256824e3a346de19240 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
```

### install and configure

```sh
# install
[root@controller ~]# yum install openstack-placement-api -y

#configure  /etc/placement/placement.conf
[root@controller ~]# cp /etc/placement/placement.conf{,.bak}
[root@controller ~]# vim /etc/placement/placement.conf
499 [placement_database]  
512 connection = mysql+pymysql://placement:placement@controller/placement 

191 [api]   
209 auth_strategy = keystone 

241 [keystone_authtoken] 
257 auth_url = http://controller:5000/v3
258 memcached_servers = controller:11211
259 auth_type = password
260 project_domain_name = Default
261 user_domain_name = Default
262 project_name = service
263 username = placement
264 password = placement  
```

填充placement数据库

```sh
[root@controller ~]# su -s /bin/sh -c "placement-manage db sync" placement
# 忽略弃用消息
```

```sh
# 重启httpd
[root@controller ~]# systemctl restart httpd
```

### 验证



插件弃用

```sh
弃用 # install osc-placement 插件 好像可以不使用
[root@controller ~]# yum install python3 -y
[root@controller ~]# wget https://bootstrap.pypa.io/pip/3.6/get-pip.py
[root@controller ~]# python3 get-pip.py 
[root@controller ~]# pip3 install osc-placement

# 其他方法
[root@controller ~]# yum install python-osc-placement -y
[root@controller ~]# openstack --os-placement-api-version 1.6 trait list --sort-column name
Expecting value: line 1 column 1 (char 0) # 因为没有apache授权

```

#### apache_BUG 

```sh
[root@controller ~]# httpd -v
Server version: Apache/2.4.6 (CentOS)
Server built:   Mar 24 2022 14:57:57


[root@controller ~]# vim /etc/httpd/conf.d/00-placement-api.conf 
[root@controller ~]# vim /etc/httpd/conf.d/00-placement-api.conf 

Listen 8778

<VirtualHost *:8778>
  WSGIProcessGroup placement-api
  WSGIApplicationGroup %{GLOBAL}
  WSGIPassAuthorization On
  WSGIDaemonProcess placement-api processes=3 threads=1 user=placement group=placement
  WSGIScriptAlias / /usr/bin/placement-api
  <IfVersion >= 2.4>
    ErrorLogFormat "%M"
  </IfVersion>
  ErrorLog /var/log/placement/placement-api.log
  #SSLEngine On
  #SSLCertificateFile ...
  #SSLCertificateKeyFile ...
</VirtualHost>

Alias /placement-api /usr/bin/placement-api
<Location /placement-api>
  SetHandler wsgi-script
  Options +ExecCGI
  WSGIProcessGroup placement-api
  WSGIApplicationGroup %{GLOBAL}
  WSGIPassAuthorization On
</Location>
# --添加的---------------------------
<Directory /usr/bin>
   <IfVersion >= 2.4>
      Require all granted
   </IfVersion>
   <IfVersion < 2.4>
      Order allow,deny
      Allow from all
   </IfVersion>
</Directory>                       

[root@controller ~]# systemctl restart httpd

```

#### 验证

```sh
# 加载admin变量
[root@controller ~]# . /server/scripts/admin-openrc 

[root@controller ~]# placement-status upgrade check
+----------------------------------+
| Upgrade Check Results            |
+----------------------------------+
| Check: Missing Root Provider IDs |
| Result: Success                  |
| Details: None                    |
+----------------------------------+
| Check: Incomplete Consumers      |
| Result: Success                  |
| Details: None                    |
+----------------------------------+
```



## Compute

### controller 端

[先决条件](###安装和配置)

```sh
# 加载admin环境变量
[root@controller ~]# . /server/scripts/admin-openrc 

# 创建 nova用户
[root@controller ~]# openstack user create --domain default --password-prompt nova
User Password:  nova
Repeat User Password:  nova
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 592315590c6c4478ab8e5a8dbb0a0f56 |
| name                | nova                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+

# 授权角色
[root@controller ~]# openstack role add --project service --user nova admin

# 创建nova实体
[root@controller ~]# openstack service create --name nova --description "Openstack Compute" compute
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Openstack Compute                |
| enabled     | True                             |
| id          | 9e0d6b63987a44d4b4a161015d31d462 |
| name        | nova                             |
| type        | compute                          |
+-------------+----------------------------------+
```

创建计算api 接口

```sh
# 公共
[root@controller ~]# openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | e1b45524842f48149dcd82b3b072ef36 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9e0d6b63987a44d4b4a161015d31d462 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+

# 私有
[root@controller ~]# openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | c8b7e2ecdc214681b10559998f745d35 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9e0d6b63987a44d4b4a161015d31d462 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+

# admin
[root@controller ~]# openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 6b85398db29b4600bc0a06825669925a |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9e0d6b63987a44d4b4a161015d31d462 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+

# 检查
[root@controller ~]# openstack endpoint list
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+
| ID                               | Region    | Service Name | Service Type | Enabled | Interface | URL                         |
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+
| 3faa8f09eee24818ad7b1e484f993476 | RegionOne | keystone     | identity     | True    | public    | http://controller:5000/v3/  |
| 5caa61c4809f43d3b59c7980a1427768 | RegionOne | glance       | image        | True    | internal  | http://controller:9292      |
| 5eb7538422a24d8fbbaa93794768701c | RegionOne | keystone     | identity     | True    | internal  | http://controller:5000/v3/  |
| 6b85398db29b4600bc0a06825669925a | RegionOne | nova         | compute      | True    | admin     | http://controller:8774/v2.1 |
| 76d56baa8adc4e97840c87688ae6c1c7 | RegionOne | keystone     | identity     | True    | admin     | http://controller:5000/v3/  |
| 9a8880fcc902452aae4f856025e55716 | RegionOne | glance       | image        | True    | admin     | http://controller:9292      |
| c8b7e2ecdc214681b10559998f745d35 | RegionOne | nova         | compute      | True    | internal  | http://controller:8774/v2.1 |
| e1b45524842f48149dcd82b3b072ef36 | RegionOne | nova         | compute      | True    | public    | http://controller:8774/v2.1 |
| e43e26896255438892cbbf5846cceef3 | RegionOne | placement    | placement    | True    | public    | http://controller:8778      |
| e5519a9bd81a4c17af66aa4959a49d26 | RegionOne | placement    | placement    | True    | admin     | http://controller:8778      |
| e9a27c37d13a4bb1a884cfe24ce73201 | RegionOne | placement    | placement    | True    | internal  | http://controller:8778      |
| ec69aa7e54484d16a6e27931aa05ebc4 | RegionOne | glance       | image        | True    | public    | http://controller:9292      |
+----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+

```

#### install and configure

```sh
# install
[root@controller ~]# yum install openstack-nova-api openstack-nova-conductor openstack-nova-novncproxy openstack-nova-scheduler -y

# openstack-nova-conductor 负责数据库连接
# openstack-nova-novncproxy 负责云主机连接
# openstack-nova-scheduler 负责资源调度

# configure
[root@controller ~]# cp /etc/nova/nova.conf{,.bak}
   1 [DEFAULT]    
1361 enabled_apis=osapi_compute,metadata    

1829 [api_database]  
1844 connection=mysql+pymysql://nova:nova@controller/nova_api 

2315 [database]   
2334 connection=mysql+pymysql://nova:nova@controller/nova   

     [DEFAULT]
1587 transport_url=rabbit://openstack:openstack@controller:5672/  

1629 [api]     
1646 auth_strategy=keystone  

3204 [keystone_authtoken]  
3220 www_authenticate_uri=http://controller:5000
3221 auth_url = http://controller:5000/
3222 memcached_servers = controller:11211
3223 auth_type = password
3224 project_domain_name = Default
3225 user_domain_name = Default
3226 project_name = service
3227 username = nova
3228 password = nova

   1 [DEFAULT]  
 508 my_ip=192.168.10.200    
 816 use_neutron=true  
1169 firewall_driver=nova.virt.firewall.NoopFirewallDriver   

5887 [vnc]    
5901 enabled=true 
5925 server_listen=$my_ip
5933 server_proxyclient_address=$my_ip

2631 [glance]   
2642 api_servers=http://controller:9292  

4257 [oslo_concurrency] 
4271 lock_path=/var/lib/nova/tmp     

4763 [placement]  
4765 region_name = RegionOne
4766 project_domain_name = Default
4767 project_name = service
4768 auth_type = password
4769 user_domain_name = Default
4770 auth_url = http://controller:5000/v3
4771 username = placement
4772 password = placement    
```

填充nova-api数据库

```sh
[root@controller ~]# su -s /bin/sh -c "nova-manage api_db sync" nova
```

注册cell0数据库

```sh
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
```

创建cell1单元格

```sh
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova
1d70d3bd-2580-4227-9012-0db58e9d6a85
```

填充数据库

```sh
[root@controller ~]# su -s /bin/sh -c "nova-manage db sync" nova

[root@controller ~]# echo $?
0
```

验证 nova cell0 和 cell1 是否正确注册

```sh
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 list_cells" nova
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+
|  Name |                 UUID                 |              Transport URL               |               Database Connection               | Disabled |
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+
| cell0 | 00000000-0000-0000-0000-000000000000 |                  none:/                  | mysql+pymysql://nova:****@controller/nova_cell0 |  False   |
| cell1 | 1d70d3bd-2580-4227-9012-0db58e9d6a85 | rabbit://openstack:****@controller:5672/ |    mysql+pymysql://nova:****@controller/nova    |  False   |
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+

```

![image-20220329155306270](openstack_version2.assets/image-20220329155306270.png)

#### 完成安装

```sh
[root@controller ~]# names=(api scheduler conductor novncproxy)
[root@controller ~]# for i in ${names[@]};do systemctl enable openstack-nova-${i};systemctl start openstack-nova-${i};done

-- 检查
[root@controller ~]# for i in ${names[@]};do systemctl status openstack-nova-${i};done


[root@controller ~]# nova service-list
[root@controller ~]# nova service-list
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+
| Id                                   | Binary         | Host       | Zone     | Status  | State | Updated_at                 | Disabled Reason | Forced down |
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+
| 88bcd793-381e-48de-b4af-d3db0eb6116a | nova-scheduler | controller | internal | enabled | up    | 2022-03-29T07:54:16.000000 | -               | False       |
| 6e0dbbe4-2374-42a5-94f9-e290dd69ac55 | nova-conductor | controller | internal | enabled | up    | 2022-03-29T07:54:19.000000 | -               | False       |
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+
[root@controller ~]#  ss -lntup|grep 6080
tcp    LISTEN     0      100       *:6080                  *:*                   users:(("nova-novncproxy",pid=27413,fd=4))

```

### compute

计算节点上使用 Quick EMUlator (QEMU) 管理

#### install and configure

```sh
# install
[root@compute ~]# yum install openstack-nova-compute -y

# configure /etc/nova/nova.conf
[root@compute ~]# cp /etc/nova/nova.conf{,.bak}
[root@compute ~]# vim /etc/nova/nova.conf
   1 [DEFAULT]
1361 enabled_apis=osapi_compute,metadata  
1587 transport_url=rabbit://openstack:openstack@controller   

1629 [api] 
1646 auth_strategy=keystone   

3202 [keystone_authtoken] 
3218 www_authenticate_uri=http://controller:5000/
3219 auth_url = http://controller:5000/
3220 memcached_servers = controller:11211
3221 auth_type = password
3222 project_domain_name = Default
3223 user_domain_name = Default
3224 project_name = service
3225 username = nova
3226 password = nova  

# 启用对网络服务的支持
   1 [DEFAULT]
 508 my_ip=192.168.10.201     #计算节点的管理IP地址  
 816 use_neutron=true 
1169 firewall_driver=nova.virt.firewall.NoopFirewallDriver     

# 这里还有网络neutron 部分需要设置



# 启用和配置远程控制台访问
5885 [vnc]    
5899 enabled=true  
5923 server_listen=$my_ip 
5931 server_proxyclient_address=$my_ip 
5937 novncproxy_base_url=http://controller:6080/vnc_auto.html   
# 服务器组件侦听所有 IP 地址，代理组件仅侦听计算节点的管理接口 IP 地址。基本 URL 指示您可以使用 Web 浏览器访问此计算节点上实例的远程控制台的位置。
-- 如果访问远程控制台的 Web 浏览器位于无法解析主机名的controller主机上，则必须替换 controller为控制器节点的管理接口 IP 地址。

2629 [glance]  
2640 api_servers=http://controller:9292

4255 [oslo_concurrency] 
4269 lock_path=/var/lib/nova/tmp    


4761 [placement]   
4764 region_name = RegionOne
4765 project_domain_name = Default
4766 project_name = service
4767 auth_type = password
4768 user_domain_name = Default
4769 auth_url = http://controller:5000/v3
4770 username = placement
4771 password = placement        
```

#### 完成安装

```sh
# 确定是否支持虚拟化
[root@compute ~]# egrep -c '(vmx|svm)' /proc/cpuinfo
1

#virt_type=kvm  默认是kvm性能最好

# 如果返回值为0 计算节点不支持硬件加速，您必须配置libvirt为使用 QEMU 而不是 KVM。
/etc/nova/nova.conf文件的[libvirt]部分
[libvirt]
# ...
virt_type = qemu

# 启动
[root@compute ~]# systemctl enable libvirtd openstack-nova-compute;systemctl start libvirtd openstack-nova-compute
```

如果`nova-compute`服务无法启动，请检查 `/var/log/nova/nova-compute.log`. 该错误消息可能表明控制器节点上的防火墙正在阻止访问端口 5672。将防火墙配置为打开控制器节点上的端口 5672 并重新启动 计算节点上的服务。

```sh
# 错误处理 安装了插件才会报错
[root@controller ~]# yum install libibverbs -y
WARNING! The remote SSH server rejected X11 forwarding request.
Last login: Wed Mar 16 16:05:22 2022 from g.lan
net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory
net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)
PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory
PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)
net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory
net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)
PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory
PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)
```



#### 将计算节点添加到单元数据

控制节点运行

```sh
# 加载admin环境
[root@controller ~]# . /server/scripts/admin-openrc 

# 查看计算节点是否有计算主机
[root@controller ~]# openstack compute service list --service nova-compute
+----+--------------+---------+------+---------+-------+----------------------------+
| ID | Binary       | Host    | Zone | Status  | State | Updated At                 |
+----+--------------+---------+------+---------+-------+----------------------------+
|  5 | nova-compute | compute | nova | enabled | up    | 2022-03-29T09:16:41.000000 |
+----+--------------+---------+------+---------+-------+----------------------------+

# 手动 发现主机
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova
Found 2 cell mappings.
Skipping cell0 since it does not contain hosts.
Getting computes from cell 'cell1': 1d70d3bd-2580-4227-9012-0db58e9d6a85
Checking host mapping for compute host 'compute': 8e1e31cf-cb45-456c-9086-9d46be3244bb
Creating host mapping for compute host 'compute': 8e1e31cf-cb45-456c-9086-9d46be3244bb
Found 1 unmapped computes in cell: 1d70d3bd-2580-4227-9012-0db58e9d6a85

# nova 重启服务
# systemctl restart   openstack-nova-api.service   openstack-nova-scheduler.service  openstack-nova-conductor.service  openstack-nova-novncproxy.service
```

> 自动发现：
>
> 添加新计算节点时，必须在控制器节点上运行以注册这些新计算节点。或者，您可以在 /etc/nova/nova.conf 中设置适当的间隔 ：nova-manage cell_v2 discover_hosts 
>
> ```sh
> [scheduler]
> discover_hosts_in_cells_interval = 300
> ```

#### 验证

```sh
# 获取admin凭据
[root@controller ~]# . /server/scripts/admin-openrc 

# 列出服务组件以验证每个进程的成功启动和注册：
[root@controller ~]# openstack compute service list
+----+----------------+------------+----------+---------+-------+----------------------------+
| ID | Binary         | Host       | Zone     | Status  | State | Updated At                 |
+----+----------------+------------+----------+---------+-------+----------------------------+
|  3 | nova-scheduler | controller | internal | enabled | up    | 2022-03-29T09:23:59.000000 |
|  4 | nova-conductor | controller | internal | enabled | up    | 2022-03-29T09:24:01.000000 |
|  5 | nova-compute   | compute    | nova     | enabled | up    | 2022-03-29T09:24:01.000000 |
+----+----------------+------------+----------+---------+-------+----------------------------+

## 此输出应指示在控制器节点上启用了两个服务组件，在计算节点上启用了一个服务组件。

# 列出身份服务中的 API 端点以验证与身份服务的连接：
[root@controller ~]# openstack catalog list
+-----------+-----------+-----------------------------------------+
| Name      | Type      | Endpoints                               |
+-----------+-----------+-----------------------------------------+
| placement | placement | RegionOne                               |
|           |           |   public: http://controller:8778        |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:8778         |
|           |           | RegionOne                               |
|           |           |   internal: http://controller:8778      |
|           |           |                                         |
| glance    | image     | RegionOne                               |
|           |           |   internal: http://controller:9292      |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:9292         |
|           |           | RegionOne                               |
|           |           |   public: http://controller:9292        |
|           |           |                                         |
| nova      | compute   | RegionOne                               |
|           |           |   admin: http://controller:8774/v2.1    |
|           |           | RegionOne                               |
|           |           |   internal: http://controller:8774/v2.1 |
|           |           | RegionOne                               |
|           |           |   public: http://controller:8774/v2.1   |
|           |           |                                         |
| keystone  | identity  | RegionOne                               |
|           |           |   public: http://controller:5000/v3/    |
|           |           | RegionOne                               |
|           |           |   internal: http://controller:5000/v3/  |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:5000/v3/     |
|           |           |                                         |
+-----------+-----------+-----------------------------------------+

# 列出image服务中的image以验证与image服务的连接性：
[root@controller ~]# openstack image list
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| 19ed976e-a52f-43da-b523-fcb0a94a7b40 | cirros | active |
+--------------------------------------+--------+--------+

# 检查单元格和放置 API 是否成功运行，以及其他必要的先决条件是否到位：
[root@controller ~]#  nova-status upgrade check
+--------------------------------+
| Upgrade Check Results          |
+--------------------------------+
| Check: Cells v2                |
| Result: Success                |
| Details: None                  |
+--------------------------------+
| Check: Placement API           |
| Result: Success                |
| Details: None                  |
+--------------------------------+
| Check: Ironic Flavor Migration |
| Result: Success                |
| Details: None                  |
+--------------------------------+
| Check: Cinder API              |
| Result: Success                |
| Details: None                  |
+--------------------------------+
```



## Neutron

### controller

网络

```sh
# 加载admin变量
[root@controller ~]# . /server/scripts/admin-openrc 
[root@controller ~]# openstack user create --domain default --password-prompt neutron
User Password:   neutron
Repeat User Password:   neutron
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 70e1e160aff74e42bcdc39fc03daeda5 |
| name                | neutron                          |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+

# 将neutron用户添加到admin角色
[root@controller ~]# openstack role add --project service --user neutron admin

# 创建neutron服务实体
[root@controller ~]# openstack service create --name neutron --description "Openstack Networking" network
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Openstack Networking             |
| enabled     | True                             |
| id          | 6efea3046d784e24bb8e92ffa5884cfa |
| name        | neutron                          |
| type        | network                          |
+-------------+----------------------------------+
```



#### 创建网络服务API

```sh
# 公共
[root@controller ~]# openstack endpoint create --region RegionOne network public http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 7690681838094b2f8886c375f45e3b91 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6efea3046d784e24bb8e92ffa5884cfa |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+

# 私有
[root@controller ~]# openstack endpoint create --region RegionOne network internal http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 3a13cd8dfe2f4960a072ea9c286c0e9b |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6efea3046d784e24bb8e92ffa5884cfa |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+

# admin
[root@controller ~]# openstack endpoint create --region RegionOne network admin http://controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 4fbe351235434e38bcd196a65f148067 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6efea3046d784e24bb8e92ffa5884cfa |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
```

#### 网络选项1：（单网卡）

##### 配置服务器组件

==这里文件缺失导致很多问题，替换为官网文件==

https://docs.openstack.org/ocata/config-reference/networking/samples/neutron.conf.html

```sh
# install
[root@controller ~]# yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables  -y

# configure    /etc/neutron/neutron.conf                
[root@controller ~]# cp /etc/neutron/neutron.conf{,.bak}
[root@controller ~]# vim /etc/neutron/neutron.conf
# 配置数据库访问
 688 [database] 
 724 connection = mysql+pymysql://neutron:neutron@controller/neutron  

# 启用 Modular Layer 2 (ML2) 插件并禁用其他插件
   1 [DEFAULT]  
  31 core_plugin = ml2
  35 service_plugins = 
   
# 配置RabbitMQ 消息队列   
 534 transport_url = rabbit://openstack:openstack@controller 
  28 auth_strategy = keystone   

 808 [keystone_authtoken]  
 810 www_authenticate_uri = http://controller:5000
 811 auth_url = http://controller:5000
 812 memcached_servers = controller:11211
 813 auth_type = password
 814 project_domain_name = default
 815 user_domain_name = default
 816 project_name = service
 817 username = neutron
 818 password = neutron  

# 配置 Networking 以通知 Compute 网络拓扑更改
 123 notify_nova_on_port_status_changes = true 
 128 notify_nova_on_port_data_changes = true   

# nova 
1009 [nova]   
1010 auth_url = http://controller:5000
1011 auth_type = password
1012 project_domain_name = default
1013 user_domain_name = default
1014 region_name = RegionOne
1015 project_name = service
1016 username = nova
1017 password = nova   

# 配置锁定路径
1116 [oslo_concurrency]  
1132 lock_path = /var/lib/neutron/tmp     
```

##### 配置 Modular Layer 2 (ML2) 插件

ML2 插件使用 Linux 桥接机制为实例构建第 2 层（桥接和交换）虚拟网络基础架构

编辑 /etc/neutron/plugins/ml2/ml2_conf.ini  系统自带文件有问题

https://docs.openstack.org/ocata/config-reference/networking/samples/ml2_conf.ini.html

```sh
[root@controller ~]# cp /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak}
[root@controller ~]# vim /etc/neutron/plugins/ml2/ml2_conf.ini
101 [ml2]
110 type_drivers = flat,vlan     #启用平面和 VLAN 网络
116 tenant_network_types =       #禁用自助服务网络
121 mechanism_drivers = linuxbridge     #启用 Linux 桥接机制
127 extension_drivers = port_security       #启用端口安全扩展驱动程序

154 [ml2_type_flat]   
164 flat_networks = provider     #将提供者虚拟网络配置为平面网络

225 [securitygroup]  
242 enable_ipset = true           # 启用 ipset 以提高安全组规则的效率    
```

##### 配置 Linux 网桥代理

Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组。

编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini

https://docs.openstack.org/ocata/config-reference/networking/samples/linuxbridge_agent.ini.html

```sh
# 将提供者虚拟网络映射到提供者物理网络接口
[root@controller ~]# cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}
[root@controller ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
132 [linux_bridge] 
144 physical_interface_mappings = provider:eth0     #将提供者虚拟网络映射到提供者物理网络接口

169 [vxlan] 
178 enable_vxlan = false     #禁用 VXLAN 覆盖网络

150 [securitygroup]  
163 enable_security_group = true 
158 firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver  
#启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：
```

通过验证以下所有 sysctl 值都设置为 1，确保您的 Linux 操作系统内核支持网桥过滤器：

```sh
[root@controller ~]# vim /etc/sysctl.conf 
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1  

[root@controller ~]# lsmod |grep -i br_netfilter

[root@controller ~]# modprobe br_netfilter
[root@controller ~]# lsmod |grep -i br_netfilter
br_netfilter           22256  0 
bridge                151336  1 br_netfilter

[root@controller ~]# sysctl -p
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1

```

##### 配置 DHCP 代理

DHCP 代理为虚拟网络提供 DHCP 服务

编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作

https://docs.openstack.org/ocata/config-reference/networking/samples/dhcp_agent.ini.html

```sh
[root@controller ~]# cp /etc/neutron/dhcp_agent.ini{,.bak}
[root@controller ~]# vim /etc/neutron/dhcp_agent.ini
  1 [DEFAULT]
 17 interface_driver = linuxbridge   
 34 dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq  
 44 enable_isolated_metadata = true
```

https://docs.openstack.org/install-guide/launch-instance-networks-provider.html

https://docs.openstack.org/neutron/train/install/controller-install-rdo.html

https://docs.openstack.org/neutron/train/install/install-rdo.html





#### 网络选项2：（多网卡）

https://docs.openstack.org/neutron/train/install/controller-install-option2-rdo.html

















#### 配置元数据代理

配置元数据代理,自带配置文件缺失

https://docs.openstack.org/ocata/config-reference/networking/samples/metadata_agent.ini.html

```sh
[root@controller ~]# cp /etc/neutron/metadata_agent.ini{,.bak}
[root@controller ~]# vim /etc/neutron/metadata_agent.ini
  1 [DEFAULT]  
 23 nova_metadata_host = controller
 36 metadata_proxy_shared_secret = neutron        #元数据共享密码
  
# 配置nova服务
[root@controller ~]# vim /etc/nova/nova.conf
3999 [neutron]
4002 auth_url = http://controller:5000
4003 auth_type = password
4004 project_domain_name = default
4005 user_domain_name = default
4006 region_name = RegionOne
4007 project_name = service
4008 username = neutron
4009 password = neutron
4010 service_metadata_proxy = true
4011 metadata_proxy_shared_secret = neutron         #这里的密码是上面设置的密码跟neutron用户的密码无关
```

#### 完成安装

网络服务初始化脚本需要一个 `/etc/neutron/plugin.ini`指向 ML2 插件配置文件的软链接

```sh
[root@controller ~]# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini

# 没有这个软连接neutron服务启动失败
```

填充数据库

```sh
[root@controller ~]# su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron
```

重启nova-api

```sh
[root@controller ~]# systemctl restart openstack-nova-api
```

启动服务

```SH
# 启动
[root@controller ~]# s=(server linuxbridge-agent dhcp-agent metadata-agent)
[root@controller ~]# for i in ${s[@]};do systemctl enable neutron-$i;systemctl start neutron-$i;done

# 检查
[root@controller ~]# s=(server linuxbridge-agent dhcp-agent metadata-agent)
[root@controller ~]# for i in ${s[@]};do systemctl status neutron-$i;done
```

*如果是**网络2**还需要启动*

```sh
# systemctl enable neutron-l3-agent.service
# systemctl start neutron-l3-agent.service
```

检查

```sh
[root@controller ~]# openstack network agent list
```

[创建公共网络](####创建公共网络)

![image-20220323231541407](openstack_version2.assets/image-20220323231541407.png)

检查日志文件是否有错误

```sh
[root@controller ~]# tail -f /var/log/neutron/*.log
==> /var/log/neutron/dhcp-agent.log <==
2022-04-05 10:01:14.756 1033 ERROR neutron.agent.dhcp.agent     'to message ID %s' % msg_id)
2022-04-05 10:01:14.756 1033 ERROR neutron.agent.dhcp.agent MessagingTimeout: Timed out waiting for a reply to message ID c9aab651d1f84645a92f2a07590b4f78

==> /var/log/neutron/linuxbridge-agent.log <==
2022-04-05 10:06:09.054 4119 ERROR neutron.plugins.ml2.drivers.linuxbridge.agent.linuxbridge_neutron_agent [-] Parsing physical_interface_mappings failed: Invalid mapping: 'eth0'. Agent terminated!

==> /var/log/neutron/metadata-agent.log <==
2022-04-05 10:00:29.188 1035 ERROR neutron.agent.metadata.agent   File "/usr/lib/python2.7/site-packages/oslo_messaging/_drivers/amqpdriver.py", line 662, in _send
2022-04-05 10:00:29.188 1035 ERROR neutron.agent.metadata.agent     call_monitor_timeout)
2022-04-05 10:00:29.188 1035 ERROR neutron.agent.metadata.agent   File "/usr/lib/python2.7/site-packages/oslo_messaging/_drivers/amqpdriver.py", line 551, in wait

上面错误是因为linuxbridge-agent配置文件没有配置网络导致
[root@controller ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
132 [linux_bridge] 
144 physical_interface_mappings = provider:eth0 

[root@controller ~]# systemctl restart neutron-linuxbridge-agent.service 
[root@controller ~]# tail -f /var/log/neutron/*.log
# 重启之后在观察并没有发现错误
```



### compute

计算节点

```sh
[root@compute ~]# yum install -y openstack-neutron-linuxbridge ebtables ipset
```

配置

完整配置文件：

https://docs.openstack.org/ocata/config-reference/networking/samples/neutron.conf.html

Networking 通用组件配置包括认证机制、消息队列和插件。

```sh
# 编辑配置文件
[root@compute ~]# vim /etc/neutron/neutron.conf
[root@compute ~]# cp /etc/neutron/neutron.conf{,.bak}
[root@compute ~]# vim /etc/neutron/neutron.conf
# 在该[database]部分中，注释掉任何connection选项，因为计算节点不直接访问数据库。
   1 [DEFAULT]   
 532 transport_url = rabbit://openstack:openstack@controller         #配置RabbitMQ 消息队列访问
 
   1 [DEFAULT]
  28 auth_strategy = keystone   
   
  805 [keystone_authtoken]  
  806 www_authenticate_uri = http://controller:5000
  807 auth_url = http://controller:5000
  808 memcached_servers = controller:11211
  809 auth_type = password
  810 project_domain_name = default
  811 user_domain_name = default
  812 project_name = service
  813 username = neutron
  814 password = neutron        # 这里注意
 
1103 [oslo_concurrency]
1120 lock_path = /var/lib/neutron/tmp  
```

#### 网络1

https://docs.openstack.org/neutron/train/install/compute-install-option1-rdo.html

配置linux 网桥代理,系统自带文件缺失

https://docs.openstack.org/ocata/config-reference/networking/samples/linuxbridge_agent.ini.html

```sh
# Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组
# /etc/neutron/plugins/ml2/linuxbridge_agent.ini
[root@compute ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini 
[root@compute ~]# cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} 

[root@compute ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
132 [linux_bridge]  
144 physical_interface_mappings = provider:eth0 # 将提供者虚拟网络映射到提供者物理网络接口

169 [vxlan] 
178 enable_vxlan = false     # 禁用 VXLAN 覆盖网络
  
  # 启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：
150 [securitygroup]   
158 firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver  

# 远程复制文件到本地
[root@controller ~]# scp /etc/sysctl.d/openstack.conf compute:/etc/sysctl.d/
openstack.conf                                                                                    100%   81     6.0KB/s   00:00    

[root@compute ~]# vim /etc/sysctl.conf 
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1  

[root@compute ~]# modprobe br_netfilter
[root@compute ~]# sysctl -p
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1

```



#### 网络2

https://docs.openstack.org/neutron/train/install/compute-install-option2-rdo.html



#### 配置计算服务使用网络

```sh
# /etc/nova/nova.conf
[root@compute ~]# vim /etc/nova/nova.conf
3992 [neutron]
3993 auth_url = http://controller:5000
3994 auth_type = password
3995 project_domain_name = default
3996 user_domain_name = default
3997 region_name = RegionOne
3998 project_name = service
3999 username = neutron
4000 password = neutron   
```

#### 完成安装

```sh
# 重启nova-api
[root@compute ~]# systemctl restart openstack-nova-compute

# 启动 Linux 网桥代理并将其配置为在系统引导时启动
[root@compute ~]# systemctl enable neutron-linuxbridge-agent;systemctl start neutron-linuxbridge-agent


[root@compute ~]# tail -f /var/log/neutron/*.log
# 检查下有没有错误信息

[root@controller ~]# openstack network agent list
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+
| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+
| 10bad0b3-6199-40ea-9938-73f01af14ac8 | Linux bridge agent | compute    | None              | :-)   | UP    | neutron-linuxbridge-agent |
| 741b3f4f-95ec-40e7-96e2-69903ac6db8c | Linux bridge agent | controller | None              | :-)   | UP    | neutron-linuxbridge-agent |
| 9d3d0670-d5b1-41e1-b745-5f458c6de03a | Metadata agent     | controller | None              | :-)   | UP    | neutron-metadata-agent    |
| f962d2dd-7720-45c6-9f10-bf3a3a47f7ec | DHCP agent         | controller | nova              | :-)   | UP    | neutron-dhcp-agent        |
+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+
```

![image-20220405135834873](openstack_version2.assets/image-20220405135834873.png)





### 验证操作

https://docs.openstack.org/neutron/train/install/verify.html

控制器运行

```sh
[root@controller ~]# . /server/scripts/admin-openrc 
[root@controller ~]# openstack  extension list --network
# 列出加载的扩展以验证 neutron-server 进程是否成功启动
```

这里有很多输出，根据实际情况

![image-20220323234006358](openstack_version2.assets/image-20220323234006358.png)

您可以使用 neutron-sanity-check 命令行客户端对网络进行进一步测试

#### 网络1

```sh
# 列出代理以验证成功启动neutron代理
[root@controller ~]# openstack network agent list
```

![image-20220323234221110](openstack_version2.assets/image-20220323234221110.png)







## Dashboard

在控制节点部署安装

```sh
[root@controller ~]# yum install openstack-dashboard -y
```

编辑文件：**/etc/openstack-dashboard/local_settings**

```sh
[root@controller ~]# cp /etc/openstack-dashboard/local_settings{,.bak}
[root@controller ~]# vim /etc/openstack-dashboard/local_settings
119 OPENSTACK_HOST = "controller"  #配置仪表板在节点controller上使用 OpenStack 服务
 40 ALLOWED_HOSTS = ['controller', 'compute']       
```

> ALLOWED_HOSTS 也可以是 ['*'] 以接受所有主机。这可能对开发工作有用，但可能不安全，不应在生产中使用。

```sh
106 SESSION_ENGINE = 'django.contrib.sessions.backends.cache'  

# 配置memcached会话存储服务
102 CACHES = {
103     'default': {
104         'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
105         'LOCATION': 'controller:11211',
106     }                                       
107 }

# 启用身份 API 版本 3
129 OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOST   

# 启用对域的支持
132 OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True  

# 配置 API 版本：
134 OPENSTACK_API_VERSIONS = {
135     "identity": 3,
136     "image": 2,
137     "volume": 3,
138 }    

# 配置Default为您通过仪表板创建的用户的默认域：
140 OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"

# 配置user为您通过仪表板创建的用户的默认角色：
141 OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"

143 WEBROOT = '/dashboard'      #bug官方没有


# 如果您选择网络选项 1，请禁用对第 3 层网络服务的支持：
148 OPENSTACK_NEUTRON_NETWORK = {
149     'enable_auto_allocated_network': False,
150     'enable_distributed_router': False,
151     'enable_fip_topology_check': False,
152     'enable_lb': False,
153     'enable_firewall': False,
154     'enable_vpn': False,
155     'enable_ha_router': False,
156     'enable_ipv6': True,
157     # TODO(amotoki): Drop OPENSTACK_NEUTRON_NETWORK completely from here.
158     # enable_quotas has the different default value here.
159     #'enable_quotas': True,
160     'enable_quotas': False,
161     'enable_rbac_policy': True,
162     #'enable_router': True,
163     'enable_router': False,
165     'default_dns_nameservers': [],
166     'supported_provider_types': ['*'],
167     'segmentation_id_range': {},
168     'extra_provider_types': {},
169     'supported_vnic_types': ['*'],
170     'physical_networks': [],
171 
172 }

# 可选配置
169 TIME_ZONE = "Asia/Shanghai"        
```

将以下行添加到 /etc/httpd/conf.d/openstack-dashboard.conf 如果不包括

```sh
[root@controller ~]# vim /etc/httpd/conf.d/openstack-dashboard.conf 

  1 WSGIDaemonProcess dashboard                                                                 
  2 WSGIProcessGroup dashboard
  3 WSGISocketPrefix run/wsgi
------------------------------------
  4 WSGIApplicationGroup %{GLOBAL}
------------------------------------
  5 WSGIScriptAlias /dashboard /usr/share/openstack-dashboard/openstack_dashboard/wsgi/django.wsgi
  6 Alias /dashboard/static /usr/share/openstack-dashboard/static
  7 
  8 <Directory /usr/share/openstack-dashboard/openstack_dashboard/wsgi>
  9   Options All
 10   AllowOverride All
 11   Require all granted
 12 </Directory>
 13 
 14 <Directory /usr/share/openstack-dashboard/static>
 15   Options All
 16   AllowOverride All
 17   Require all granted
 18 </Directory>
 19 
```

安装完成

```sh
[root@controller ~]# systemctl restart httpd.service memcached.service
```

验证

验证仪表板的操作。

使用 Web 浏览器访问仪表板 `http://controller/dashboard`。

使用`admin`或`demo`用户和`default`域凭据进行身份验证。

http://172.16.0.200/dashboard/ 访问

域：default     user:admin   password:admin

![image-20220405142751658](openstack_version2.assets/image-20220405142751658.png)

存储配置：https://docs.openstack.org/cinder/stein/install/

# 启动实例

上面把必备组件API都搭建好了，现在是要怎么去使用。

先决条件:必须有虚拟网络支持

网络1：公网  网络2：私网

## 创建虚拟网络

### 公网

#### 创建公共网络

参考：https://docs.openstack.org/install-guide/launch-instance-networks-provider.html

在启动实例之前，您必须创建必要的虚拟网络基础架构。对于网络选项 1，实例通过第 2 层（桥接/交换）连接到物理网络基础设施的提供商（外部）网络。该网络包括一个 DHCP 服务器，可为实例提供 IP 地址。

该admin或其他特权用户必须创建此网络，因为它直接连接到物理网络基础设施。

> 以下说明和图表使用示例 IP 地址范围。您必须针对您的特定环境调整它们。

![网络选项 1：提供商网络 - 概述](openstack_version2.assets/network1-overview.png)



**网络选项 1：提供商网络 - 概述**

![网络选项 1：提供商网络 - 连接](openstack_version2.assets/network1-connectivity.png)

**网络选项 1：提供商网络 - 连接**

#### 创建提供者网络

```sh
# 获取admin 变量
[root@controller ~]# . /server/scripts/admin-openrc 

# 创建网路
[root@controller ~]# openstack network create  --share --external --provider-physical-network provider --provider-network-type flat provider
+---------------------------+-----------------------------------------------+
| Field                     | Value                                         |
+---------------------------+-----------------------------------------------+
| admin_state_up            | UP                                            |
| availability_zone_hints   |                                               |
| availability_zones        |                                               |
| created_at                | 2022-04-05T06:49:46Z                          |
| description               |                                               |
| dns_domain                | None                                          |
| id                        | eeb204f5-f63a-469b-b8ef-62d38d309f55          |
| ipv4_address_scope        | None                                          |
| ipv6_address_scope        | None                                          |
| is_default                | None                                          |
| is_vlan_transparent       | None                                          |
| location                  | cloud='', project.domain_id=, project.domain_name='Default', project.id='81e9a381f87f4a9a9c4ac1bc39248b67', project.name='admin', region_name='', zone= |
| mtu                       | 1500                                          |
| name                      | provider                                      |
| port_security_enabled     | True                                          |
| project_id                | 81e9a381f87f4a9a9c4ac1bc39248b67              |
| provider:network_type     | flat                                          |
| provider:physical_network | provider                                      |
| provider:segmentation_id  | None                                          |
| qos_policy_id             | None                                          |
| revision_number           | 1                                             |
| router:external           | External                                      |
| segments                  | None                                          |
| shared                    | True                                          |
| status                    | ACTIVE                                        |
| subnets                   |                                               |
| tags                      |                                               |
| updated_at                | 2022-04-05T06:49:47Z                          |
+---------------------------+-----------------------------------------------+


# 查看创建好的网络
[root@controller ~]# openstack network list
+--------------------------------------+----------+---------+
| ID                                   | Name     | Subnets |
+--------------------------------------+----------+---------+
| eeb204f5-f63a-469b-b8ef-62d38d309f55 | provider |         |
+--------------------------------------+----------+---------+
```

`--share`选项允许所有项目使用虚拟网络

`--external`选项将虚拟网络定义为外部网络。如果你想创建一个内部网络，你可以使用`--internal`。默认值为`internal`。

==--provider-physical-network== provider 和 --provider-network-type flat 选项使用以下文件中的信息将平面虚拟网络连接到主机上 eth1 接口上的平面（本机/未标记）物理网络：

```sh
# ml2_conf.ini：
[ml2_type_flat]
flat_networks = provider   #已经设置

# linuxbridge_agent.ini
[linux_bridge]
physical_interface_mappings = provider:eth0  #已经设置过
```

在网络上创建子网：

```sh
 openstack subnet create --network provider \
  --allocation-pool start=START_IP_ADDRESS,end=END_IP_ADDRESS \
  --dns-nameserver DNS_RESOLVER --gateway PROVIDER_NETWORK_GATEWAY \
  --subnet-range PROVIDER_NETWORK_CIDR provider
```

用 CIDR 表示法的提供商物理网络上的==子网==替换 PROVIDER_NETWORK_CIDR。

将 ==START_IP_ADDRESS== 和 ==END_IP_ADDRESS== 替换为您要为实例分配的子网范围内的第一个和最后一个 IP 地址。此范围不得包含任何现有的活动 IP 地址。

--allocation-pool  DHCP 池

将 ==DNS_RESOLVER== 替换为 DNS 解析器的 IP 地址。在大多数情况下，您可以使用主机上 /etc/resolv.conf 文件中的一个

将 ==PROVIDER_NETWORK_GATEWAY== 替换为提供商网络上的网关 IP 地址，通常是“.1”IP 地址。

**例子**

提供商网络使用 203.0.113.0/24 和 203.0.113.1 上的网关。DHCP 服务器为每个实例分配一个从 203.0.113.101 到 203.0.113.250 的 IP 地址。所有实例都使用 8.8.4.4 作为 DNS 解析器。

```sh
[root@controller ~]# openstack subnet create --network provider --allocation-pool start=172.16.0.205,end=172.16.0.250 --dns-nameserver 8.8.4.4 --gateway 172.16.0.1 --subnet-range 172.16.0.0/24 provider
+-------------------+---------------------------------------------------+
| Field             | Value                                             |
+-------------------+---------------------------------------------------+
| allocation_pools  | 172.16.0.205-172.16.0.250                         |
| cidr              | 172.16.0.0/24                                     |
| created_at        | 2022-04-05T06:59:44Z                              |
| description       |                                                   |
| dns_nameservers   | 8.8.4.4                                           |
| enable_dhcp       | True                                              |
| gateway_ip        | 172.16.0.1                                        |
| host_routes       |                                                   |
| id                | 448ae0eb-f78b-4515-b462-0968932f6a24              |
| ip_version        | 4                                                 |
| ipv6_address_mode | None                                              |
| ipv6_ra_mode      | None                                              |
| location          | cloud='', project.domain_id=, project.domain_name='Default', project.id='81e9a381f87f4a9a9c4ac1bc39248b67', project.name='admin', region_name='', zone= |
| name              | provider                                          |
| network_id        | eeb204f5-f63a-469b-b8ef-62d38d309f55              |
| prefix_length     | None                                              |
| project_id        | 81e9a381f87f4a9a9c4ac1bc39248b67                  |
| revision_number   | 0                                                 |
| segment_id        | None                                              |
| service_types     |                                                   |
| subnetpool_id     | None                                              |
| tags              |                                                   |
| updated_at        | 2022-03-20T03:17:35Z                              |
+-------------------+---------------------------------------------------+


[root@controller ~]# openstack network list
+--------------------------------------+----------+--------------------------------------+
| ID                                   | Name     | Subnets                              |
+--------------------------------------+----------+--------------------------------------+
| eeb204f5-f63a-469b-b8ef-62d38d309f55 | provider | 448ae0eb-f78b-4515-b462-0968932f6a24 |
+--------------------------------------+----------+--------------------------------------+

# 查看子网
[root@controller ~]# openstack subnet list
+--------------------------------------+----------+--------------------------------------+---------------+
| ID                                   | Name     | Network                              | Subnet        |
+--------------------------------------+----------+--------------------------------------+---------------+
| 448ae0eb-f78b-4515-b462-0968932f6a24 | provider | eeb204f5-f63a-469b-b8ef-62d38d309f55 | 172.16.0.0/24 |
+--------------------------------------+----------+--------------------------------------+---------------+

[root@controller ~]# openstack network list
+--------------------------------------+----------+--------------------------------------+
| ID                                   | Name     | Subnets                              |
+--------------------------------------+----------+--------------------------------------+
| eeb204f5-f63a-469b-b8ef-62d38d309f55 | provider | 448ae0eb-f78b-4515-b462-0968932f6a24 |
+--------------------------------------+----------+--------------------------------------+

```

创建提供商网络：https://docs.openstack.org/install-guide/launch-instance.html#launch-instance-networks

遵循通用安装指南中的[此提供商网络文档](https://docs.openstack.org/install-guide/launch-instance-networks-provider.html)。



### 私网

https://docs.openstack.org/install-guide/launch-instance-networks-selfservice.html

选择网络选项 2，您还可以创建一个通过 NAT 连接到物理网络基础设施的自助（专用）网络。该网络包括一个 DHCP 服务器，可为实例提供 IP 地址。此网络上的实例可以自动访问外部网络，例如 Internet。但是，从 Internet 等外部网络访问此网络上的实例需要[浮动 IP 地址](https://docs.openstack.org/install-guide/common/glossary.html#term-floating-IP-address)。

![网络选项 2：自助服务网络 - 概述](openstack_version2.assets/network2-overview.png)

**网络选项 2：自助服务网络 - 概述**

![网络选项 2：自助服务网络 - 连接](openstack_version2.assets/network2-connectivity.png)

**网络选项 2：自助服务网络 - 连接**

#### 创建私网

在controller 操作

```sh
# . demo-openrc
#  openstack network create selfservice


ml2_conf.ini
[ml2]
tenant_network_types = vxlan

[ml2_type_vxlan]
vni_ranges = 1:1000


# 在网络上创建子网
openstack subnet create --network selfservice \
  --dns-nameserver DNS_RESOLVER --gateway SELFSERVICE_NETWORK_GATEWAY \
  --subnet-range SELFSERVICE_NETWORK_CIDR selfservice
```

替换`DNS_RESOLVER`为 DNS 解析器的 IP 地址。在大多数情况下，您可以使用`/etc/resolv.conf`主机上文件中的一个。

替换`SELFSERVICE_NETWORK_GATEWAY`为您要在自助服务网络上使用的网关，通常是“.1”IP 地址。

替换`SELFSERVICE_NETWORK_CIDR`为要在自助服务网络上使用的子网。您可以使用任意值，尽管我们推荐使用[RFC 1918](https://tools.ietf.org/html/rfc1918)中的网络。

```
例子：
openstack subnet create --network selfservice \
  --dns-nameserver 8.8.4.4 --gateway 172.16.1.1 \
  --subnet-range 172.16.1.0/24 selfservice
```

#### 创建路由

自助服务网络使用通常执行双向 NAT 的虚拟路由器连接到提供商网络。每个路由器都包含至少一个自助服务网络上的接口和提供商网络上的网关。

提供者网络必须包含`router:external`使自助服务路由器能够将其用于连接到外部网络（例如 Internet）的选项。该`admin`或其他特权用户必须在网络创建期间包含此选项或稍后添加。在这种情况下，该 `router:external`选项是`--external`在创建`provider`网络时使用参数设置的。

```sh
$ . demo-openrc
$ openstack router create router
```

将自助服务网络子网添加为路由器上的接口：

```sh
$ openstack router add subnet router selfservice

# 在路由器的提供商网络上设置网关
$ openstack router set router --external-gateway provider
```

#### 验证

```sh
$ . admin-openrc
$ ip netns   # 列出网络命名空间。您应该看到一个qrouter命名空间和两个 qdhcp命名空间。

# 列出路由器上的端口以确定提供商网络上的网关 IP 地址：
$ openstack port list --router router

# 从控制器节点或物理提供商网络上的任何主机 ping 此 IP 地址：能ping通说明正常
```

## 创建flavor

实体类型

预设最小配置m1.nano,内存64m 

```sh
[root@controller ~]# openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano
+----------------------------+---------+
| Field                      | Value   |
+----------------------------+---------+
| OS-FLV-DISABLED:disabled   | False   |
| OS-FLV-EXT-DATA:ephemeral  | 0       |
| disk                       | 1       |
| id                         | 0       |
| name                       | m1.nano |
| os-flavor-access:is_public | True    |
| properties                 |         |
| ram                        | 64      |
| rxtx_factor                | 1.0     |
| swap                       |         |
| vcpus                      | 1       |
+----------------------------+---------+
```

![image-20220327101144291](openstack_version2.assets/image-20220327101144291.png)

这里可以多预设几种

```sh
[root@controller ~]# openstack flavor create --id 1 --vcpus 1 --ram 128 --disk 2 m2.nano
[root@controller ~]# openstack flavor create --id 2 --vcpus 1 --ram 512 --disk 5 m3.nano
[root@controller ~]# openstack flavor create --id 3 --vcpus 1 --ram 1024 --disk 5 m4.nano
[root@controller ~]# openstack flavor create --id 4 --vcpus 2 --ram 2048 --disk 10 m5.nano
```

![image-20220327101540666](openstack_version2.assets/image-20220327101540666.png)

我们购买阿里云或者其他云主机的时候这些是通过自定义购买的

## 生成密钥对

大多数云镜像支持[公钥认证](https://docs.openstack.org/install-guide/common/glossary.html#term-public-key-authentication)，而不是传统的密码认证。在启动实例之前，您必须向计算服务添加一个公钥。

用户不同就要生成对应的密钥

```sh
[root@controller ~]# . /server/scripts/demo-openrc 

# 没有就生成，这里我配置了免密登录到对方所以这里使用ssh-keygen命令并使用现有的公钥。
[root@controller ~]# ssh-keygen -q -N ""

# 添加公钥：
[root@controller ~]# openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey
+-------------+-------------------------------------------------+
| Field       | Value                                           |
+-------------+-------------------------------------------------+
| fingerprint | 18:89:d0:13:8b:68:89:61:29:ab:c5:cd:4c:16:ed:63 |
| name        | mykey                                           |
| user_id     | 712d99082a9c4244a10aeae357d84c09                |
+-------------+-------------------------------------------------+


# 验证密钥对
[root@controller ~]# openstack keypair list
+-------+-------------------------------------------------+
| Name  | Fingerprint                                     |
+-------+-------------------------------------------------+
| mykey | 39:80:4e:d1:93:21:5d:d8:1b:d0:fd:2b:50:9e:47:f4 |

```

## 安全组

默认情况下，`default`安全组适用于所有实例，并包含拒绝远程访问实例的防火墙规则。对于 CirrOS 等 Linux 映像，我们建议至少允许 ICMP (ping) 和安全 shell (SSH)。

`default`向安全组添加规则：

```sh
# 允许ICM ping
[root@controller ~]# openstack security group rule create --proto icmp default
+-------------------+--------------------------------------------+
| Field             | Value                                      |
+-------------------+--------------------------------------------+
| created_at        | 2022-03-27T02:24:18Z                       |
| description       |                                            |
| direction         | ingress                                    |
| ether_type        | IPv4                                       |
| id                | 0726ebf5-32bc-49ca-981c-03674e9e123e       |
| location          | cloud='', project.domain_id=, project.domain_name='Default', project.id='d8a0a1caeb7c4a24b9172583d5334f73', project.name='myproject', region_name='', zone= |
| name              | None                                       |
| port_range_max    | None                                       |
| port_range_min    | None                                       |
| project_id        | d8a0a1caeb7c4a24b9172583d5334f73           |
| protocol          | icmp                                       |
| remote_group_id   | None                                       |
| remote_ip_prefix  | 0.0.0.0/0                                  |
| revision_number   | 0                                          |
| security_group_id | b48fe240-defe-4363-8e02-64b264e3cd71       |
| tags              | []                                         |
| updated_at        | 2022-03-27T02:24:18Z                       |
+-------------------+--------------------------------------------+

# 允许ssh访问
[root@controller ~]# openstack security group rule create --proto tcp --dst-port 22 default
+-------------------+--------------------------------------------+
| Field             | Value                                      |
+-------------------+--------------------------------------------+
| created_at        | 2022-03-27T02:26:33Z                       |
| description       |                                            |
| direction         | ingress                                    |
| ether_type        | IPv4                                       |
| id                | 08f715f6-3ac3-456a-919e-ff98d6aa2688       |
| location          | cloud='', project.domain_id=, project.domain_name='Default', project.id='d8a0a1caeb7c4a24b9172583d5334f73', project.name='myproject', region_name='', zone= |
| name              | None                                       |
| port_range_max    | 22                                         |
| port_range_min    | 22                                         |
| project_id        | d8a0a1caeb7c4a24b9172583d5334f73           |
| protocol          | tcp                                        |
| remote_group_id   | None                                       |
| remote_ip_prefix  | 0.0.0.0/0                                  |
| revision_number   | 0                                          |
| security_group_id | b48fe240-defe-4363-8e02-64b264e3cd71       |
| tags              | []                                         |
| updated_at        | 2022-03-27T02:26:33Z                       |
+-------------------+--------------------------------------------+

```

> 上面是先决条件，要满足上面的条件才能启动实例

## 启动实例

### 公网启动实例

使用demo环境创建

```sh
# 加载凭证
[root@controller ~]# . /server/scripts/demo-openrc 

# 查看规格
[root@controller ~]# openstack flavor list 
+----+---------+------+------+-----------+-------+-----------+
| ID | Name    |  RAM | Disk | Ephemeral | VCPUs | Is Public |
+----+---------+------+------+-----------+-------+-----------+
| 0  | m1.nano |   64 |    1 |         0 |     1 | True      |
| 1  | m2.nano |  128 |    2 |         0 |     1 | True      |
| 2  | m3.nano |  512 |    5 |         0 |     1 | True      |
| 3  | m4.nano | 1024 |    5 |         0 |     1 | True      |
| 4  | m5.nano | 2048 |   10 |         0 |     2 | True      |
+----+---------+------+------+-----------+-------+-----------+

# 查看可以使用镜像
[root@controller ~]# openstack image list
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| 6b5fb395-33f1-410c-84a0-8f0bf9061fde | cirros | active |
+--------------------------------------+--------+--------+

# 查看网络
[root@controller ~]# openstack network list
+--------------------------------------+----------+--------------------------------------+
| ID                                   | Name     | Subnets                              |
+--------------------------------------+----------+--------------------------------------+
| eeb204f5-f63a-469b-b8ef-62d38d309f55 | provider | 448ae0eb-f78b-4515-b462-0968932f6a24 |
+--------------------------------------+----------+--------------------------------------+

# ！！！ 实例使用provider提供商网络。但是，您必须使用 ID 而不是名称来引用此网络。

# 查看已有安全组
[root@controller ~]# openstack security group list
+--------------------------------------+---------+------------------------+----------------------------------+------+
| ID                                   | Name    | Description            | Project                          | Tags |
+--------------------------------------+---------+------------------------+----------------------------------+------+
| b7290cc4-0f93-46d9-ac47-a6614f2c54d5 | default | Default security group | e970d927dd1d4872a3d6904203ef548a | []   |
+--------------------------------------+---------+------------------------+----------------------------------+------+

```

上面都具备就可以启动实例了

```sh
openstack server create --flavor m1.nano --image cirros \
  --nic net-id=PROVIDER_NET_ID --security-group default \
  --key-name mykey provider-instance
# PROVIDER_NET_ID 替换为provider ID

# 如果您选择选项 1 并且您的环境仅包含一个网络，则可以省略该--nic选项，因为 OpenStack 会自动选择唯一可用的网络。
openstack server create --flavor m1.nano --image cirros \
  --nic net-id=eeb204f5-f63a-469b-b8ef-62d38d309f55 --security-group default \
  --key-name mykey provider-instance
  
[root@controller ~]# openstack server create --flavor m1.nano --image cirros \
   --nic net-id=eeb204f5-f63a-469b-b8ef-62d38d309f55 --security-group default \
   --key-name mykey provider-instance
+-----------------------------+-----------------------------------------------+
| Field                       | Value                                         |
+-----------------------------+-----------------------------------------------+
| OS-DCF:diskConfig           | MANUAL                                        |
| OS-EXT-AZ:availability_zone |                                               |
| OS-EXT-STS:power_state      | NOSTATE                                       |
| OS-EXT-STS:task_state       | scheduling                                    |
| OS-EXT-STS:vm_state         | building                                      |
| OS-SRV-USG:launched_at      | None                                          |
| OS-SRV-USG:terminated_at    | None                                          |
| accessIPv4                  |                                               |
| accessIPv6                  |                                               |
| addresses                   |                                               |
| adminPass                   | fE46gq5TGvkN                                  |
| config_drive                |                                               |
| created                     | 2022-04-05T07:10:28Z                          |
| flavor                      | m1.nano (0)                                   |
| hostId                      |                                               |
| id                          | 48facd0e-b09b-4366-977b-aa5c79853246          |
| image                       | cirros (19ed976e-a52f-43da-b523-fcb0a94a7b40) |
| key_name                    | mykey                                         |
| name                        | provider-instance                             |
| progress                    | 0                                             |
| project_id                  | e970d927dd1d4872a3d6904203ef548a              |
| properties                  |                                               |
| security_groups             | name='b7290cc4-0f93-46d9-ac47-a6614f2c54d5'   |
| status                      | BUILD                                         |
| updated                     | 2022-04-05T07:10:28Z                          |
| user_id                     | 712d99082a9c4244a10aeae357d84c09              |
| volumes_attached            |                                               |
+-----------------------------+-----------------------------------------------+


# 检查实例状态
[root@controller ~]# openstack server list
+--------------------------------------+-------------------+--------+----------+--------+---------+
| ID                                   | Name              | Status | Networks | Image  | Flavor  |
+--------------------------------------+-------------------+--------+----------+--------+---------+
| 6f8f4748-96e9-4061-b5d2-ef065735cf05 | provider-instance | BUILD  |          | cirros | m1.nano |
+--------------------------------------+-------------------+--------+----------+--------+---------+
# 当构建过程成功完成时，BUILD状态会发生变化。ACTIVE
[root@controller ~]# openstack server list
+--------------------------------------+-------------------+--------+-----------------------+--------+---------+
| ID                                   | Name              | Status | Networks              | Image  | Flavor  |
+--------------------------------------+-------------------+--------+-----------------------+--------+---------+
| 48facd0e-b09b-4366-977b-aa5c79853246 | provider-instance | ACTIVE | provider=172.16.0.222 | cirros | m1.nano |
+--------------------------------------+-------------------+--------+-----------------------+--------+---------+

```

#### 使用vnc访问实例

```sh
[root@controller ~]# openstack console url show provider-instance
+-------+-------------------------------------------------------------------------------------------+
| Field | Value                                                                                     |
+-------+-------------------------------------------------------------------------------------------+
| type  | novnc                                                                                     |
| url   | http://controller:6080/vnc_auto.html?path=%3Ftoken%3D5426a750-4913-4905-8e40-719cc4fe7249 |
+-------+-------------------------------------------------------------------------------------------+
# controller 如果不能访问那就需要使用IP地址了。
```

![image-20220405163534640](openstack_version2.assets/image-20220405163534640.png)

```sh
[root@controller ~]# ping -c 3 172.16.0.222
PING 172.16.0.222 (172.16.0.222) 56(84) bytes of data.
From 172.16.0.200 icmp_seq=1 Destination Host Unreachable
From 172.16.0.200 icmp_seq=2 Destination Host Unreachable
From 172.16.0.200 icmp_seq=3 Destination Host Unreachable

# 检查网络连接情况测试虚拟机启动情况。可以看到不通
```

查看服务器支持的虚拟化类型

> [root@compute ~]# virsh capabilities

```sh
[root@compute ~]# virsh capabilities
<capabilities>

  <host>
    <uuid>679d4d56-2cc0-4794-fa5f-34171df4394c</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-noTSX-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='45'/>
      <counter name='tsc' frequency='2194920000' scaling='no'/>
      <topology sockets='1' cores='1' threads='1'/>
      <feature name='vme'/>
      <feature name='ss'/>
      <feature name='vmx'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='hypervisor'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='arch-facilities'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='no'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='1'>
        <cell id='0'>
          <memory unit='KiB'>1863004</memory>
          <pages unit='KiB' size='4'>465751</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
          </distances>
          <cpus num='1'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='3' unit='MiB' cpus='0'/>
    </cache>
    <secmodel>
      <model>selinux</model>
      <doi>0</doi>
      <baselabel type='kvm'>system_u:system_r:svirt_t:s0</baselabel>
      <baselabel type='qemu'>system_u:system_r:svirt_tcg_t:s0</baselabel>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+107:+107</baselabel>
      <baselabel type='qemu'>+107:+107</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/libexec/qemu-kvm</emulator>
      <machine maxCpus='240'>pc-i440fx-rhel7.6.0</machine>
      <machine canonical='pc-i440fx-rhel7.6.0' maxCpus='240'>pc</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.0.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.6.0</machine>
      <machine canonical='pc-q35-rhel7.6.0' maxCpus='384'>q35</machine>
      <machine maxCpus='240'>rhel6.3.0</machine>
      <machine maxCpus='240'>rhel6.4.0</machine>
      <machine maxCpus='240'>rhel6.0.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.5.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.1.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.2.0</machine>
      <machine maxCpus='255'>pc-q35-rhel7.3.0</machine>
      <machine maxCpus='240'>rhel6.5.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.4.0</machine>
      <machine maxCpus='240'>rhel6.6.0</machine>
      <machine maxCpus='240'>rhel6.1.0</machine>
      <machine maxCpus='240'>rhel6.2.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.3.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.4.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.5.0</machine>
      <domain type='qemu'/>
      <domain type='kvm'>
        <emulator>/usr/libexec/qemu-kvm</emulator>
      </domain>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <pae/>
      <nonpae/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/libexec/qemu-kvm</emulator>
      <machine maxCpus='240'>pc-i440fx-rhel7.6.0</machine>
      <machine canonical='pc-i440fx-rhel7.6.0' maxCpus='240'>pc</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.0.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.6.0</machine>
      <machine canonical='pc-q35-rhel7.6.0' maxCpus='384'>q35</machine>
      <machine maxCpus='240'>rhel6.3.0</machine>
      <machine maxCpus='240'>rhel6.4.0</machine>
      <machine maxCpus='240'>rhel6.0.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.5.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.1.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.2.0</machine>
      <machine maxCpus='255'>pc-q35-rhel7.3.0</machine>
      <machine maxCpus='240'>rhel6.5.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.4.0</machine>
      <machine maxCpus='240'>rhel6.6.0</machine>
      <machine maxCpus='240'>rhel6.1.0</machine>
      <machine maxCpus='240'>rhel6.2.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.3.0</machine>
      <machine maxCpus='240'>pc-i440fx-rhel7.4.0</machine>
      <machine maxCpus='384'>pc-q35-rhel7.5.0</machine>
      <domain type='qemu'/>
      <domain type='kvm'>
        <emulator>/usr/libexec/qemu-kvm</emulator>
      </domain>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>
```

#### 更改nova



不是真机不用修改

```sh
[root@compute ~]# vim /etc/nova/nova.conf
3376 [libvirt]    
3618 hw_machine_type=x86_64=pc-i440fx-rhel7.6.0  #更改虚拟化类型
3568 cpu_mode=host-passthrough         # 直接使用主机的CPU                                                                           
[root@compute ~]# systemctl restart openstack-nova-*
```

![image-20220405164938120](openstack_version2.assets/image-20220405164938120.png)

查看日志有没有报错的信息

```sh
[root@compute ~]# tail -f -n 50 /var/log/nova/nova-compute.log 
```

![image-20220405165931129](openstack_version2.assets/image-20220405165931129.png)

控制台出现上面的提示

```sh
[root@compute ~]# vim /etc/nova/nova.conf
3415 virt_type=qemu  

systemctl restart openstack-nova*
```

cirros 默认启动的用户cirros 

![image-20220405203104426](openstack_version2.assets/image-20220405203104426.png)

![image-20220405204505978](openstack_version2.assets/image-20220405204505978.png)

*可以看出虚拟机网络和实体机网络通了*

```sh
[root@compute ~]# ssh cirros@172.16.0.216   # 测试22端口
The authenticity of host '172.16.0.216 (172.16.0.216)' can't be established.
ECDSA key fingerprint is SHA256:WF9rx09WufrmKN89WVgUCq/DHfDxafc1CySkPxrmHTI.
ECDSA key fingerprint is MD5:19:0a:60:ae:eb:2a:c4:5b:93:64:5a:1a:60:ad:25:69.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.16.0.216' (ECDSA) to the list of known hosts.
cirros@172.16.0.216's password: 

$ ping -c 3 172.16.0.119
PING 172.16.0.119 (172.16.0.119): 56 data bytes
64 bytes from 172.16.0.119: seq=0 ttl=128 time=12.955 ms
64 bytes from 172.16.0.119: seq=1 ttl=128 time=3.859 ms
64 bytes from 172.16.0.119: seq=2 ttl=128 time=2.014 ms

--- 172.16.0.119 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 2.014/6.276/12.955 ms
```

这里是ping 我的windows10 系统

![image-20220405222002281](openstack_version2.assets/image-20220405222002281.png)

到这里openstack 搭建基本上是成功了。





### 私网启动实例

https://docs.openstack.org/install-guide/launch-instance-selfservice.html

配置方法都差不多



# 存储添加

https://docs.openstack.org/cinder/train/install/

https://docs.openstack.org/cinder/train/install/index-rdo.html

存储很关键的部分，首先需要一个稳定的存储系统才可以实现下面的操作。



## 添加块存储

https://docs.openstack.org/install-guide/launch-instance-cinder.html



# 防火墙和默认端口

https://docs.openstack.org/install-guide/firewalls-default-ports.html



镜像https://docs.openstack.org/image-guide/obtain-images.html#centos

http://cloud.centos.org/centos/7/images/



搭建已经完成剩下的基本上都是一些定制化的开发了。

